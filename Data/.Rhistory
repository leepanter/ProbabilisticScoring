set.seed(123)
index.list[[1]]=sample(index.sample.set, N.obs, replace = FALSE)
View(index.list)
index.vec[i]=index.list[[i]]
unlist(index.list[[1]])
index.vec=c()
append(index.vec, index.list[[1]])
# phq9DataSubsetImport.R
# Imports PHQ9 Data Subst from original data set
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Data"
setwd(WD)
phq9=read.csv(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Data/PHQ9subset.csv")
save(phq9, file = "phq9.Rdata")
# phq9DataSubsetImport.R
# Imports PHQ9 Data Subst from original data set
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Data"
setwd(WD)
phq9=read.csv(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Data/PHQ9subset.csv")
####	Libraries and Prelims	 ####
set.seed(123)
dat.in=phq9
N.set=3
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
index.dat.in=list()
dat.train.out=list()
index.list[[1]]=sample(index.sample.set, N.obs, replace = FALSE)
View(index.list)
index.vec[1]=append(index.vec, index.list[[1]])
index.list
index.list[[1]]
index.vec=append(index.vec, index.list[[1]])
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
index.dat.in=list()
dat.train.out=list()
index.list[[1]]=sample(index.sample.set, N.obs, replace = FALSE)
View(index.list)
index.vec=append(index.vec, index.list[[1]])
index.dat.in[[1]]=dat.in[index.list[[1]],]
index.sample.set=index.fixed.set[-index.vec]
i=i+1
length(index.sample.set)
index.list[[2]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, index.list[[i]])
index.dat.in[[i]]=dat.in[index.list[[i]],]
View(index.list)
View(index.dat.in)
index.sample.set=index.fixed.set[-index.vec[i]]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
length(index.sample.set)>=N.obs
length(index.sample.set)
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
index.dat.in=list()
dat.train.out=list()
while(length(index.sample.set)>=N.obs){
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, index.list[[i]])
index.dat.in[[i]]=dat.in[index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
}
# phq9DataSubsetImport.R
# Imports PHQ9 Data Subst from original data set
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Data"
setwd(WD)
phq9=read.csv(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Data/PHQ9subset.csv")
dat.in=phq9
N.set=3
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
index.dat.in=list()
dat.train.out=list()
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, index.list[[i]])
index.dat.in[[i]]=dat.in[index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
View(index.list)
index.vec=append(index.vec, index.list[[i]])
index.dat.in[[i]]=dat.in[index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
dat.in=phq9
N.set=3
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
index.dat.in=list()
dat.train.out=list()
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, index.list[[i]])
index.dat.in[[i]]=dat.in[index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
index.dat.in[[i]]=dat.in[index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
index.dat.in[[i]]=dat.in[index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
dat.in=phq9
N.set=3
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
dat.train.out=list()
dat.test.out=list()
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
View(index.list)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
# phq9DataSubsetImport.R
# Imports PHQ9 Data Subst from original data set
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Data"
setwd(WD)
phq9=read.csv(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Data/PHQ9subset.csv")
# functionCVsplit.R
# Description: This script defines the function CVsplit, which takes as arguments:
####	Arguments
# dat.in: Data set to partition
# N.set: Number of sets (total, including test set) into which to partition data
####  Return (Type=list())
# format: list(dat.train.out, dat.test.out, N.obs)
# out.list <-- Contains the elements below
# dat.train.out: a list of training data sets (in order of selection)
# dat.test.out: a list of testing data sets (in order of selection)
# N.obs: a numerical value indicating the number of observations in a training/test set
#
####  Call:
#  obj = CVsplit(mydat, N)
####	Libraries and Prelims	 ####
set.seed(123)
####	Begin Script	 ####
CVsplit=function(dat.in, N.set){
# Test for N.set >=2
if(N.set<2){return(0)}
else{
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
dat.train.out=list()
dat.test.out=list()
while(i<=N.set){
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
}
out.list=list(dat.train.out,
dat.test.out,
N.obs)
}
}
####	End Script	 ####
CVsplit(phq9, 10)
x=CVsplit(phq9, 10)
View(x)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
####	Libraries and Prelims	 ####
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
####	Begin Script	 ####
CVsplit=function(dat.in, N.set){
# Test for N.set >=2
if(N.set<2){return(0)}
else{
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
dat.train.out=list()
dat.test.out=list()
while(i<=N.set){
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
}
out.list=list(dat.train.out,
dat.test.out,
N.obs)
}
}
####	Libraries and Prelims	 ####
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
x=CVsplit(phq9, 20)
x[[1]]
View(x)
x=CVsplit(phq9, 20)
x[[1]][[2]]
x=CVsplit(phq9, 2)
View(x)
x=CVsplit(phq9, 4)
View(x)
x=CVsplit(phq9, 8)
View(x)
x=CVsplit(phq9, 20)
View(x)
124*20
2480
2480+124
x[[2]][[1]]
dat.in=x[[2]][[1]]
View(dat.in)
colnames(dat.in)
dat.in=dat.in[,2:32]
colnames(dat.in)
dat.in=dat.in[,-c(3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21)]
colnames(dat.in)
dat.in=dat.in[,-13]
qNum=1
respNum=0
colnames(dat.in)
colnames(dat.in)[3:12]=c("qTot", "Q1", "Q2", "Q3", "Q4", "Q5", "Q6", "Q7", "Q8", "Q9")
dat.in$Q1=dat.in$Q1-1
dat.in$Q2=dat.in$Q2-1
dat.in$Q3=dat.in$Q3-1
dat.in$Q4=dat.in$Q4-1
dat.in$Q5=dat.in$Q5-1
dat.in$Q6=dat.in$Q6-1
dat.in$Q7=dat.in$Q7-1
dat.in$Q8=dat.in$Q8-1
dat.in$Q9=dat.in$Q9-1
#colnames(dat.in)[3:12]=c("qTot", "Q1", "Q2", "Q3", "Q4", "Q5", "Q6", "Q7", "Q8", "Q9")
# dat.in$Q1=dat.in$Q1-1
# dat.in$Q2=dat.in$Q2-1
# dat.in$Q3=dat.in$Q3-1
# dat.in$Q4=dat.in$Q4-1
# dat.in$Q5=dat.in$Q5-1
# dat.in$Q6=dat.in$Q6-1
# dat.in$Q7=dat.in$Q7-1
# dat.in$Q8=dat.in$Q8-1
# dat.in$Q9=dat.in$Q9-1
dat.in$qTot=sum(dat.in[,4:12])
which(dat.in$qTot<=7)
which(dat.in$qTot < 7)
class(dat.in$qTot)
which(dat.in[,3] <7)
dat.in[,3]
View(dat.in)
# Imports PHQ9 Data Subst from original data set
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Data"
setwd(WD)
phq9=read.csv(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Data/PHQ9subset.csv")
save(phq9, file = "phq9.Rdata")
View(phq9)
dat.in=dat.in[,2:32]
dat.in=dat.in[,-c(3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21)]
dat.in=dat.in[,-13]
x=CVsplit(phq9, 20)
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
View(phq9)
# phq9DataSubsetImport.R
# Imports PHQ9 Data Subst from original data set
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Data"
setwd(WD)
phq9=read.csv(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Data/PHQ9subset.csv")
save(phq9, file = "phq9.Rdata")
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
View(phq9)
dat.in=phq9
dat.in=dat.in[,2:32]
dat.in=dat.in[,-c(3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21)]
dat.in=dat.in[,-13]
colnames(dat.in)[3:12]=c("qTot", "Q1", "Q2", "Q3", "Q4", "Q5", "Q6", "Q7", "Q8", "Q9")
View(dat.in)
dat.in$Q1=dat.in$Q1-1
dat.in$Q2=dat.in$Q2-1
dat.in$Q3=dat.in$Q3-1
dat.in$Q4=dat.in$Q4-1
dat.in$Q5=dat.in$Q5-1
dat.in$Q6=dat.in$Q6-1
dat.in$Q7=dat.in$Q7-1
dat.in$Q8=dat.in$Q8-1
dat.in$Q9=dat.in$Q9-1
View(dat.in)
dat.in$qTot=sum(dat.in[,4:12])
dat.in=phq9
dat.in=dat.in[,2:32]
dat.in=dat.in[,-c(3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21)]
dat.in=dat.in[,-13]
colnames(dat.in)[3:12]=c("qTot", "Q1", "Q2", "Q3", "Q4", "Q5", "Q6", "Q7", "Q8", "Q9")
dat.in$Q1=dat.in$Q1-1
dat.in$Q2=dat.in$Q2-1
dat.in$Q3=dat.in$Q3-1
dat.in$Q4=dat.in$Q4-1
dat.in$Q5=dat.in$Q5-1
dat.in$Q6=dat.in$Q6-1
dat.in$Q7=dat.in$Q7-1
dat.in$Q8=dat.in$Q8-1
dat.in$Q9=dat.in$Q9-1
View(dat.in)
resp.list=list()
for(i in 1:2495)
dat.in$Q1[1]
for(i in 1:2495){
resp.list[[i]]=c(dat.in$Q1[i],
dat.in$Q2[i],
dat.in$Q3[i],
dat.in$Q4[i],
dat.in$Q5[i],
dat.in$Q6[i],
dat.in$Q7[i],
dat.in$Q8[i],
dat.in$Q9[i])
}
View(resp.list)
resp.list[[1]]
tot.vec=c()
for(i in 1:2495){
tot.vec[i]=sum(unlist(resp.list[[i]]))
}
dat.in$qTot=tot.vec
save(dat.in, file = "datin.Rdata")
####	Libraries and Prelims	 ####
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
View(dat.in)
x=CVsplit(dat.in, 20)
View(x)
dat.in=x[[2]][[1]]
# Calculate Prior Proababilities
PC1=which(dat.in$qTot<7)
PC1=which(dat.in$qTot<7)
# Calculate Prior Proababilities
PC1.index=which(dat.in$qTot<7)
Ntot=length(dat.in[,4])
qNum=1
respNum=0
# Figure out which columns correspond to answers to qNum
index.qNum=which(colnames(dat.in)==qNum)
index.qNum=which(colnames(dat.in)=="Q1")
Ntot=length(dat.in[,index.qNum])
qDat=dat.in[,index.qNum]
PC1.index=which(dat.in$qTot<7 & qDat==respNum)
PrPc1=length(PC1.index)
PC2.index=which(7<=dat.in$qTot & dat.in$qTot<10 & qDat==respNum)
PrPc2=length(PC2.index)
PC3.index=which(dat.in$qTot >= 10 & qDat==respNum)
PrPc3=length(PC3.index)
PrPc1+PrPc2+PrPc3
PqRespNum=length(which(qDat==respNum))
ret1=PrPc1/PqRespNum
ret2=PrPc2/PqRespNum
ret3=PrPc3/PqRespNum
out=c(ret1, ret2, ret3)
return(out)
InitEvalAtt=functio(dat.in, qNum, respNum, qName){
# InitEvalAtt(DataName,
#  QuestionNumber (numeric),
#  ResponseNumber (numeric),
#  "qName" (String))
# Figure out which columns correspond to answers to qNum
index.qNum=which(colnames(dat.in)==qName)
qDat=dat.in[,index.qNum]
# Calculate Prior Proababilities
PC1.index=which(dat.in$qTot<7 & qDat==respNum)
PrPc1=length(PC1.index)
PC2.index=which(7<=dat.in$qTot & dat.in$qTot<10 & qDat==respNum)
PrPc2=length(PC2.index)
PC3.index=which(dat.in$qTot >= 10 & qDat==respNum)
PrPc3=length(PC3.index)
PqRespNum=length(which(qDat==respNum))
ret1=PrPc1/PqRespNum
ret2=PrPc2/PqRespNum
ret3=PrPc3/PqRespNum
out=c(ret1, ret2, ret3)
return(out)
}
InitEvalAtt=functio(dat.in, qNum, respNum, qName){
# InitEvalAtt(DataName,
#  QuestionNumber (numeric),
#  ResponseNumber (numeric),
#  "qName" (String))
# Figure out which columns correspond to answers to qNum
index.qNum=which(colnames(dat.in)==qName)
qDat=dat.in[,index.qNum]
# Calculate Prior Proababilities
PC1.index=which(dat.in$qTot<7 & qDat==respNum)
PrPc1=length(PC1.index)
PC2.index=which(7<=dat.in$qTot & dat.in$qTot<10 & qDat==respNum)
PrPc2=length(PC2.index)
PC3.index=which(dat.in$qTot >= 10 & qDat==respNum)
PrPc3=length(PC3.index)
PqRespNum=length(which(qDat==respNum))
ret1=PrPc1/PqRespNum
ret2=PrPc2/PqRespNum
ret3=PrPc3/PqRespNum
out=c(ret1, ret2, ret3)
return(out)
}
InitEvalAtt=functio(dat.in, qNum, respNum, qName){
# InitEvalAtt(DataName,
#  QuestionNumber (numeric),
#  ResponseNumber (numeric),
#  "qName" (String))
# Figure out which columns correspond to answers to qNum
index.qNum=which(colnames(dat.in)==qName)
qDat=dat.in[,index.qNum]
# Calculate Prior Proababilities
PC1.index=which(dat.in$qTot<7 & qDat==respNum)
PrPc1=length(PC1.index)
PC2.index=which(7<=dat.in$qTot & dat.in$qTot<10 & qDat==respNum)
PrPc2=length(PC2.index)
PC3.index=which(dat.in$qTot >= 10 & qDat==respNum)
PrPc3=length(PC3.index)
PqRespNum=length(which(qDat==respNum))
ret1=PrPc1/PqRespNum
ret2=PrPc2/PqRespNum
ret3=PrPc3/PqRespNum
out=c(ret1, ret2, ret3)
return(out)
}
InitEvalAtt=function(dat.in, qNum, respNum, qName){
# InitEvalAtt(DataName,
#  QuestionNumber (numeric),
#  ResponseNumber (numeric),
#  "qName" (String))
# Figure out which columns correspond to answers to qNum
index.qNum=which(colnames(dat.in)==qName)
qDat=dat.in[,index.qNum]
# Calculate Prior Proababilities
PC1.index=which(dat.in$qTot<7 & qDat==respNum)
PrPc1=length(PC1.index)
PC2.index=which(7<=dat.in$qTot & dat.in$qTot<10 & qDat==respNum)
PrPc2=length(PC2.index)
PC3.index=which(dat.in$qTot >= 10 & qDat==respNum)
PrPc3=length(PC3.index)
PqRespNum=length(which(qDat==respNum))
ret1=PrPc1/PqRespNum
ret2=PrPc2/PqRespNum
ret3=PrPc3/PqRespNum
out=c(ret1, ret2, ret3)
return(out)
}
InitEvalAtt(dat.in, 3, 2, "Q3")
InitEvalAtt(dat.in, 9, 3, "Q9")
