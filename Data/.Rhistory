# N.set: Number of sets (total, including test set) into which to partition data
####  Return (Type=list())
# format: list(dat.train.out, dat.test.out, N.obs)
# out.list <-- Contains the elements below
# dat.train.out: a list of training data sets (in order of selection)
# dat.test.out: a list of testing data sets (in order of selection)
# N.obs: a numerical value indicating the number of observations in a training/test set
####  Call:
#  obj = CVsplit(mydat, N)
####	Libraries and Prelims	 ####
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9"
setwd(WD)
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
####	Begin Script	 ####
CVsplit=function(dat.in, N.set){
# Test for N.set >=2
if(N.set<2){return(0)}
else{
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
dat.train.out=list()
dat.test.out=list()
while(i<=N.set){
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
}
out.list=list(dat.train.out,
dat.test.out,
N.obs)
}
}
####	End Script	 ####
# functionCVsplit.R
# Description: This script defines the function CVsplit, which takes as arguments:
####	Arguments
# dat.in: Data set to partition
# N.set: Number of sets (total, including test set) into which to partition data
####  Return (Type=list())
# format: list(dat.train.out, dat.test.out, N.obs)
# out.list <-- Contains the elements below
# dat.train.out: a list of training data sets (in order of selection)
# dat.test.out: a list of testing data sets (in order of selection)
# N.obs: a numerical value indicating the number of observations in a training/test set
####  Call:
#  obj = CVsplit(mydat, N)
####	Libraries and Prelims	 ####
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9"
setwd(WD)
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
####	Begin Script	 ####
CVsplit=function(dat.in, N.set){
# Test for N.set >=2
if(N.set<2){return(0)}
else{
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
dat.train.out=list()
dat.test.out=list()
while(i<=N.set){
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
}
out.list=list(dat.train.out,
dat.test.out,
N.obs)
}
}
####	End Script	 ####
# functionPeval.R
####  Description:  This script calculated the probabilities of being classified into one of three different outcome categories based upon training data.
####  Arguments:
# dat.in: training data file on which to perform calculations
# qNum: question number of inquiry
# respNum: given response of inquiry
# qName: Column String name for response of interest Q1, Q2, Q3...
####  Retuns:
# a three-item vector of probabilites corresponding to the chances of eventually being characterized within a certain classification outcome C1, C2, C3
####	Libraries and Prelims	 ####
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
####	Begin Script	 ####
# Deine categorical separation points
Peval=function(dat.in, qNum, respNum, qName){
# InitEvalAtt(DataName,
#  QuestionNumber (numeric),
#  ResponseNumber (numeric),
#  "qName" (String))
low.thresh=7
high.thresh=10
# Figure out which columns correspond to answers to qNum
index.qNum=which(colnames(dat.in)==qName)
qDat=dat.in[,index.qNum]
# Calculate Prior Proababilities
PC1.index=which(dat.in$qTot<low.thresh & qDat==respNum)
PrPc1=length(PC1.index)
PC2.index=which(low.thresh<=dat.in$qTot & dat.in$qTot<high.thresh & qDat==respNum)
PrPc2=length(PC2.index)
PC3.index=which(dat.in$qTot >= high.thresh & qDat==respNum)
PrPc3=length(PC3.index)
PqRespNum=length(which(qDat==respNum))
ret1=PrPc1/PqRespNum
ret2=PrPc2/PqRespNum
ret3=PrPc3/PqRespNum
out=c(ret1, ret2, ret3)
return(out)
}
####	End Script	 ####
x=2000
x=2495
N.obs=500
N.sets=floor(x/N.obs)
N=2495
N.sets=2:2495
N.obs=floor(N/N.sets)
N.obs.train=N.obs.train*(N.sets-1)
N.obs.train=N.obs*(N.sets-1)
plot(N.obs.train~N.sets)
lines(N.obs.train~N.sets)
2495/2000
2495/2
# phq9DataSubsetImport.R
# Imports PHQ9 Data Subst from original data set
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Data"
setwd(WD)
phq9=read.csv(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Data/PHQ9subset.csv")
dat.in=phq9
dat.in=dat.in[,2:32]
dat.in=dat.in[,-c(3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21)]
dat.in=dat.in[,-13]
colnames(dat.in)[3:12]=c("qTot", "Q1", "Q2", "Q3", "Q4", "Q5", "Q6", "Q7", "Q8", "Q9")
dat.in$Q1=dat.in$Q1-1
dat.in$Q2=dat.in$Q2-1
dat.in$Q3=dat.in$Q3-1
dat.in$Q4=dat.in$Q4-1
dat.in$Q5=dat.in$Q5-1
dat.in$Q6=dat.in$Q6-1
dat.in$Q7=dat.in$Q7-1
dat.in$Q8=dat.in$Q8-1
dat.in$Q9=dat.in$Q9-1
resp.list=list()
for(i in 1:2495){
resp.list[[i]]=c(dat.in$Q1[i],
dat.in$Q2[i],
dat.in$Q3[i],
dat.in$Q4[i],
dat.in$Q5[i],
dat.in$Q6[i],
dat.in$Q7[i],
dat.in$Q8[i],
dat.in$Q9[i])
}
tot.vec=c()
for(i in 1:2495){
tot.vec[i]=sum(unlist(resp.list[[i]]))
}
dat.in$qTot=tot.vec
phq9Subset=dat.in
save(phq9Subset, file = "phq9Subset.Rdata")
save(dat.in, file = "datin.Rdata")
rm(dat.in)
rm(i)
rm(WD)
knitr::opts_chunk$set(echo=FALSE,
cache = TRUE,
fig.align = "center",
fig.width = 5)
N.sets.choice=c()
N=2495
N.obs.choice=1:2495
N.sets.choice=floor(N/N.obs.choice)
N.train.sets=c()
N.train.sets=N.sets.choice-1
N.obs.train=N.train.sets*N.obs.choice
N.obs=N.obs.train
hist(N.obs.train)
plot(N.obs~N.sets.choice)
hist(N.sets.choice)
N.sets=c()
N=2495
N.obs.choice=1:2495
N.obs=1:2495
N.sets=c()
N=2495
N.obs=1:2495
N.sets=floor(N/N.obs)
N.train.sets=N.sets-1
N.obs.train=N.sets*N.obs
plot(N.sets~N.obs.train)
plot(N.sets~N.obs.train)
lines(N.sets~N.obs.train)
lines(N.sets~N.obs.train)
plot.new()
lines(N.sets~N.obs.train)
####  Libraries and Preliminaries
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
source(file="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPeval.R")
data.in=phq9Subset
N.PCV.ob=100
init.dat.in=dat.in
N.rows=dim(init.dat.in)[1]
init.dat.in=dat.in
dat.in=phq9Subset
N.PCV.ob=100
init.dat.in=dat.in
N.rows=dim(init.dat.in)[1]
in.N.PCV.obs=N.PCV.obs
N.PCV.obs=100
init.dat.in=dat.in
N.rows=dim(init.dat.in)[1]
in.N.PCV.obs=N.PCV.obs
init.N.set=floor(N.row/in.N.PCV.obs)
N.row=dim(init.dat.in)[1]
in.N.PCV.obs=N.PCV.obs
init.N.set=floor(N.row/in.N.PCV.obs)
init.N.set=floor(N.row/in.N.PCV.obs)
dat.out=CVsplit(init.dat.in, init.N.set)
View(dat.out)
dat.out[[1]][[1]]
Peval(dat.out[[1]][[1]],1,0,"Q1")
string1="Q1"
Peval(dat.out[[1]][[1]],1,0,string1)
string1="Q2"
string1="Q2"
Peval(dat.out[[1]][[1]],1,0,string1)
stringVec=c("Q1","Q2","Q3","Q4","Q5","Q6","Q7","Q8","Q9")
Peval(dat.out[[1]][[1]],1,0,stringVec[1])
dat.in=dat.out[[1]][[1]]
Qnum=1
Qstring=stringVec[1]
#PCeval_overQnum=function(dat.in, Qnum, Qstring){
init.dat.in=dat.in
init.Qnum=Qnum
init.Qstring=Qstring
subject.length=dim(init.dat.in)[1]
out.Sub_i=list()
for(i in 1:subject.length){
out.Resp_k=list()
for(k in 1:4){
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k, initi.Qstring)
}
}
k=1
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k, init.Qstring)
View(out.Resp_k)
k=2
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k, init.Qstring)
View(out.Resp_k)
k=3
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k, init.Qstring)
View(out.Resp_k)
k=4
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k, init.Qstring)
View(out.Resp_k)
i=1
out.Sub_i[[i]]=list(out.Resp_k[[1]],
out.Resp_k[[2]],
out.Resp_k[[3]],
out.Resp_k[[4]])
View(out.Sub_i)
View(out.Resp_k)
k=4
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k, init.Qstring)
View(out.Sub_i)
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k-1, init.Qstring)
View(out.Resp_k)
for(k in 1:4){
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k-1, init.Qstring)
}
View(out.Resp_k)
for(i in 1:subject.length){
out.Resp_k=list()
for(k in 1:4){
out.Resp_k[[k]]=Peval(init.dat.in, init.Qnum, k-1, init.Qstring)
}
out.Sub_i[[i]]=list(out.Resp_k[[1]],
out.Resp_k[[2]],
out.Resp_k[[3]],
out.Resp_k[[4]])
}
View(out.Sub_i)
# functionPCVeval.R
####  Description: This script defines a function that evaluates Peval for a input training data size.  This function is specific to PHQ9 data that is subsetted and reformatted for the specific use of this, and further functions.
####  Arguments:
# data.in: A way to pass in PHQ9 data
# N.PCV.obs: Number of observations contained in training data sets, passed into CVsplit() function for CV data partitioning.
####  Returns: (Type=list())
# format: list(C1.PCV.out, C2.PCV.out, C3.PCV.out)
####  Libraries and Preliminaries
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
source(file="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPeval.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPCVeval_overQnum.R")
# phq9DataSubsetImport.R
# Imports PHQ9 Data Subst from original data set
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Data"
setwd(WD)
phq9=read.csv(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Data/PHQ9subset.csv")
dat.in=phq9
dat.in=dat.in[,2:32]
dat.in=dat.in[,-c(3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21)]
dat.in=dat.in[,-13]
colnames(dat.in)[3:12]=c("qTot", "Q1", "Q2", "Q3", "Q4", "Q5", "Q6", "Q7", "Q8", "Q9")
dat.in$Q1=dat.in$Q1-1
dat.in$Q2=dat.in$Q2-1
dat.in$Q3=dat.in$Q3-1
dat.in$Q4=dat.in$Q4-1
dat.in$Q5=dat.in$Q5-1
dat.in$Q6=dat.in$Q6-1
dat.in$Q7=dat.in$Q7-1
dat.in$Q8=dat.in$Q8-1
dat.in$Q9=dat.in$Q9-1
resp.list=list()
for(i in 1:2495){
resp.list[[i]]=c(dat.in$Q1[i],
dat.in$Q2[i],
dat.in$Q3[i],
dat.in$Q4[i],
dat.in$Q5[i],
dat.in$Q6[i],
dat.in$Q7[i],
dat.in$Q8[i],
dat.in$Q9[i])
}
Qstring=c("Q1","Q2","Q3","Q4","Q5","Q6","Q7","Q8","Q9")
tot.vec=c()
for(i in 1:2495){
tot.vec[i]=sum(unlist(resp.list[[i]]))
}
dat.in$qTot=tot.vec
phq9Subset=dat.in
save(phq9Subset, file = "phq9Subset.Rdata")
save(dat.in, file = "datin.Rdata")
rm(dat.in)
rm(i)
rm(WD)
training data size.  This function is specific to PHQ9 data that is subsetted and reformatted for the specific use of this, and further functions.
####  Arguments:
# data.in: A way to pass in PHQ9 data
# N.PCV.obs: Number of observations contained in training data sets, passed into CVsplit() function for CV data partitioning.
####  Returns: (Type=list())
# format: list(C1.PCV.out, C2.PCV.out, C3.PCV.out)
####  Libraries and Preliminaries
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
source(file="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPeval.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPCVeval_overQnum.R")
dat.in=phq9Subset
N.PCV.obs=100
init.dat.in=dat.in
N.row=dim(init.dat.in)[1]
in.N.PCV.obs=N.PCV.obs
dat.out=CVsplit(init.dat.in, init.N.set)
dat.in=phq9Subset
N.PCV.obs=100
init.dat.in=dat.in
in.N.PCV.obs=N.PCV.obs
init.N.set=floor(N.row/in.N.PCV.obs)
N.row=dim(init.dat.in)[1]
dat.out=CVsplit(init.dat.in, init.N.set)
View(dat.out)
dat.out.OverQnum=PCeval_overQnum(dat.out[[1]][[1]], 1, Qstring[1])
####  Libraries and Preliminaries
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
source(file="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPeval.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPCVeval_overQnum.R")
dat.in=phq9Subset
N.PCV.obs=100
init.dat.in=dat.in
in.N.PCV.obs=N.PCV.obs
init.N.set=floor(N.row/in.N.PCV.obs)
N.row=dim(init.dat.in)[1]
dat.out=CVsplit(init.dat.in, init.N.set)
dat.out.OverQnum=PCeval_overQnum(dat.out[[1]][[1]], 1, Qstring[1])
View(dat.out.OverQnum)
CVsplit(phq9Subset,2495)
x=CVsplit(phq9Subset,2495)
View(x)
x=CVsplit(phq9Subset,0)
x=CVsplit(phq9Subset,1)
x=CVsplit(phq9Subset,1)
View(resp.list)
x=CVsplit(phq9Subset,1)
x=CVsplit(phq9Subset,2495)
View(x)
x=CVsplit(phq9Subset,0)
# functionCVsplit.R
# Description: This script defines the function CVsplit, which takes as arguments:
####	Arguments
# dat.in: Data set to partition
# N.set: Number of sets (total, including test set) into which to partition data
####  Return (Type=list())
# format: list(dat.train.out, dat.test.out, N.obs)
# out.list <-- Contains the elements below
# dat.train.out: a list of training data sets (in order of selection)
# dat.test.out: a list of testing data sets (in order of selection)
# N.obs: a numerical value indicating the number of observations in a training/test set
####  Call:
#  obj = CVsplit(mydat, N)
####	Libraries and Prelims	 ####
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9"
setwd(WD)
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
####	Begin Script	 ####
CVsplit=function(dat.in, N.set){
if(N.set==2496)
{return(list(dat.in))}
else{
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
dat.train.out=list()
dat.test.out=list()
while(i<=N.set){
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
}
out.list=list(dat.train.out,
dat.test.out,
N.obs)
return(out.list)
}
}
####	End Script	 ####
x=CVsplit(phq9Subset,2496)
View(x)
x2=CVsplit(phq9Subset,5)
View(x2)
# functionPCVeval.R
####  Description: This script defines a function that evaluates Peval for a input training data size.  This function is specific to PHQ9 data that is subsetted and reformatted for the specific use of this, and further functions.
####  Arguments:
# data.in: A way to pass in PHQ9 data
# N.PCV.obs: Number of observations contained in training data sets, passed into CVsplit() function for CV data partitioning.
####  Returns: (Type=list())
# format: list(C1.PCV.out, C2.PCV.out, C3.PCV.out)
####  Libraries and Preliminaries
set.seed(123)
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/functionCVsplit.R")
source(file="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPeval.R")
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionPCVeval_overQnum.R")
dat.in=phq9Subset
N.PCV.obs=100
init.dat.in=dat.in
in.N.PCV.obs=N.PCV.obs
init.N.set=floor(N.row/in.N.PCV.obs)
N.row=dim(init.dat.in)[1]
N.row=dim(init.dat.in)[1]
init.N.set=floor(N.row/in.N.PCV.obs)
dat.out=CVsplit(init.dat.in, init.N.set)
dat.out.OverQnum=PCeval_overQnum(dat.out[[1]][[1]], 1, Qstring[1])
View(dat.out.OverQnum)
dat.in=phq9Subset
N.PCV.obs=2496
init.dat.in=dat.in
in.N.PCV.obs=N.PCV.obs
N.row=dim(init.dat.in)[1]
init.N.set=floor(N.row/in.N.PCV.obs)
dat.out=CVsplit(init.dat.in, init.N.set)
dat.out=CVsplit(init.dat.in, N.PCV.obs)
dat.in=phq9Subset
N.PCV.obs.full=2496
N.PCV.ob=1000
init.dat.in=dat.in
in.N.PCV.obs.full=N.PCV.obs.full
in.N.PCV.obs=N.PCV.obs
dat.out.full=CVsplit(init.dat.in, N.PCV.obs.full)
dat.out=CVsplit(init.dat.in, N.PCV.ob)
View(dat.out.full)
View(dat.out)
dat.out.OverQnum=PCeval_overQnum(dat.out[[1]][[1]], 1, Qstring[1])
dat.out.OverQnum.full=PCeval_overQnum(dat.out.full[[1]], 1, Qstring[1])
View(dat.out.OverQnum)
View(dat.out.OverQnum.full)
