CVk_j.data.accuracy.traditional[j]=length(which(CVk_j.test[[j]]$sumClassNum==CVk_j.test[[j]]$SupOutNum))/Number.k.obs
}
####  Output Accuracy Values
CVk.accuracy=mean(CVk_j.data.accuracy)
accuracy.ksets[k.index]=CVk.accuracy
CVk.accuracy.traditional=mean(CVk_j.data.accuracy.traditional)
traditional.accuracy.ksets[k.index]=CVk.accuracy.traditional
N.obs.k[k.index]=Number.k.obs*(k.setVal-1)
}
N.obs.k=c()
for(k in 1:50){
N.obs.k[k]=dim(boot.sample.i[[k]][[1]][[1]])
}
accuracy.df=data.frame(N.obs.k, accuracy.ksets)
zeros=rep(0, times=50)
ones=rep(1, times=50)
ID=as.factor(c(ones, zeros))
N.obs.train.k.lmFE=rep(N.obs.k, times=2)
accuracy.out.lmFE=c(accuracy.ksets,traditional.accuracy.ksets)
accuracy.df.lmFE=data.frame(N.obs.train.k, ID, accuracy.out)
accuracy.lm=lm(accuracy.out~N.obs.train.k, data = accuracy.df)
(accuracy.lms=summary(accuracy.lm))
accuracy.lmFE=lm(accuracy.out.lmFE~ID*N.obs.train.k.lmFE,
data = accuracy.df.lmFE)
(accuracy.lmFEs=summary(accuracy.lmFE))
accuracy.plot=ggplot(accuracy.df, aes(x=N.obs.k, y=accuracy.ksets))+
xlab("Observations in Traing Set")+
ylab("Accuracy of Prob.Scoring")+
geom_abline(intercept = as.numeric(coef(accuracy.lm))[[1]],
slope=as.numeric(coef(accuracy.lm))[[2]])+
geom_point()
accuracy.plot
plot(accuracy.lm)
####  This Portion will now generalize to arbitrary k values
accuracy.ksets=c()
traditional.accuracy.ksets=c()
N.obs.k=c()
#lower.loop.limit=1225
#upper.loop.limit=1275
N.set.arg=seq(from=1248, to=2490, length.out = 14)
N.set.arg=c(N.set.arg,1247)
for(i in 1:15){
N.set.arg[i]=floor(N.set.arg[i])
}
boot.sample.i=list()
for(i in 1:15){
boot.sample.i[[i]]=CVsplit(phq9, N.set.arg[i])
}
for(k in 1:15){
k.setVal=N.set.arg[k]
k.index=k
####	Divide Data into K CV data sets
#CVk.dat=CVsplit(phq9, k.setVal)
CVk.dat=boot.sample.i[[k.index]]
Number.k.obs=CVk.dat[[3]]
####  Initialized Empty Variables
CVk_j.train=list()
CVk_j.test=list()
CVk_j.train.weights=list()
CVk_j.data.accuracy=c()
CVk_j.data.accuracy.traditional=c()
for(j in 1:k.setVal){
CVk_j.train[[j]]=CVk.dat[[1]][[j]]
CVk_j.test[[j]]=CVk.dat[[2]][[j]]
CVk_j.probClasses=c()
CVk_j.probClasses.Convg=list()
### Calculate data weights
CVk_j.train.weights[[j]]=ReformatWeights(PCVeval_overQnum(CVk_j.train[[j]]))
for(i in 1:3){
CVk_j.train.weights[[j]][[i]]=round(CVk_j.train.weights[[j]][[i]], digits = 4)
}
###  Calculate CVk-j probabilistic outcomes
CVk_j.probSequences=EvalSeqSubject(CVk_j.train.weights[[j]], CVk_j.test[[j]], 1)
for(i in 1:Number.k.obs){
CVk_j.probClasses.Convg[[i]]=convg(CVk_j.probSequences[[i]], 0.75)
}
for(i in 1:Number.k.obs){
CVk_j.probClasses[i]=CVk_j.probClasses.Convg[[i]][[3]]
}
####  Calculate Accuracy of probablistic classes
CVk_j.data.accuracy[j]=length(which(CVk_j.probClasses==CVk_j.test[[j]]$SupOutNum))/Number.k.obs
####  Calculate Accuracy of traditional Classes
CVk_j.data.accuracy.traditional[j]=length(which(CVk_j.test[[j]]$sumClassNum==CVk_j.test[[j]]$SupOutNum))/Number.k.obs
}
####  Output Accuracy Values
CVk.accuracy=mean(CVk_j.data.accuracy)
accuracy.ksets[k.index]=CVk.accuracy
CVk.accuracy.traditional=mean(CVk_j.data.accuracy.traditional)
traditional.accuracy.ksets[k.index]=CVk.accuracy.traditional
N.obs.k[k.index]=Number.k.obs*(k.setVal-1)
}
View(CVk.dat)
View(CVk.dat)
####  This Portion will now generalize to arbitrary k values
accuracy.ksets=c()
traditional.accuracy.ksets=c()
N.obs.k=c()
#lower.loop.limit=1225
#upper.loop.limit=1275
N.set.arg=seq(from=1248, to=2490, length.out = 14)
N.set.arg=c(N.set.arg,1247)
for(i in 1:15){
N.set.arg[i]=floor(N.set.arg[i])
}
boot.sample.i=list()
for(i in 1:15){
boot.sample.i[[i]]=CVsplit(phq9, N.set.arg[i])
}
View(boot.sample.i)
View(boot.sample.i)
for(k in 1:15){
k.setVal=N.set.arg[k]
k.index=k
####	Divide Data into K CV data sets
#CVk.dat=CVsplit(phq9, k.setVal)
CVk.dat=boot.sample.i[[k.index]]
Number.k.obs=CVk.dat[[3]]
####  Initialized Empty Variables
CVk_j.train=list()
CVk_j.test=list()
CVk_j.train.weights=list()
CVk_j.data.accuracy=c()
CVk_j.data.accuracy.traditional=c()
for(j in 1:k.setVal){
CVk_j.train[[j]]=CVk.dat[[1]][[j]]
CVk_j.test[[j]]=CVk.dat[[2]][[j]]
CVk_j.probClasses=c()
CVk_j.probClasses.Convg=list()
### Calculate data weights
CVk_j.train.weights[[j]]=ReformatWeights(PCVeval_overQnum(CVk_j.train[[j]]))
for(i in 1:3){
CVk_j.train.weights[[j]][[i]]=round(CVk_j.train.weights[[j]][[i]], digits = 4)
}
###  Calculate CVk-j probabilistic outcomes
CVk_j.probSequences=EvalSeqSubject(CVk_j.train.weights[[j]], CVk_j.test[[j]], 1)
for(i in 1:Number.k.obs){
CVk_j.probClasses.Convg[[i]]=convg(CVk_j.probSequences[[i]], 0.75)
}
for(i in 1:Number.k.obs){
CVk_j.probClasses[i]=CVk_j.probClasses.Convg[[i]][[3]]
}
####  Calculate Accuracy of probablistic classes
CVk_j.data.accuracy[j]=length(which(CVk_j.probClasses==CVk_j.test[[j]]$SupOutNum))/Number.k.obs
####  Calculate Accuracy of traditional Classes
CVk_j.data.accuracy.traditional[j]=length(which(CVk_j.test[[j]]$sumClassNum==CVk_j.test[[j]]$SupOutNum))/Number.k.obs
}
####  Output Accuracy Values
CVk.accuracy=mean(CVk_j.data.accuracy)
accuracy.ksets[k.index]=CVk.accuracy
CVk.accuracy.traditional=mean(CVk_j.data.accuracy.traditional)
traditional.accuracy.ksets[k.index]=CVk.accuracy.traditional
N.obs.k[k.index]=Number.k.obs*(k.setVal-1)
}
N.obs.k=c()
for(k in 1:15){
N.obs.k[k]=dim(boot.sample.i[[k]][[1]][[1]])
}
accuracy.df=data.frame(N.obs.k, accuracy.ksets)
save(accuracy.df, file = "/Users/lee/Desktop/CVk15.Rdata")
plot(accuracy.ksets~N.obs.k)
View(accuracy.df)
View(accuracy.df)
View(boot.sample.i)
boot.sample.i[[2]][[1]][[1]]
N.obs.k=c()
for(k in 1:15){
N.obs.k[k]=dim(boot.sample.i[[k]][[1]][[1]])[1]
}
dim(boot.sample.i[[15]][[1]][[1]])
length(boot.sample.i[[15]][[1]])
N.obs.k=c()
for(k in 1:15){
N.obs.k[k]=length(boot.sample.i[[k]][[1]])
}
accuracy.df=data.frame(N.obs.k, accuracy.ksets)
save(accuracy.df, file = "/Users/lee/Desktop/CVk15.Rdata")
accuracy.plot=ggplot(accuracy.df, aes(x=N.obs.k, y=accuracy.ksets))+
xlab("Observations in Traing Set")+
ylab("Accuracy of Prob.Scoring")+
geom_abline(intercept = as.numeric(coef(accuracy.lm))[[1]],
slope=as.numeric(coef(accuracy.lm))[[2]])+
geom_point()
plot(accuracy.ksets~N.obs.k)
accuracy.df=data.frame(N.obs.k, accuracy.ksets)
zeros=rep(0, times=50)
ones=rep(1, times=50)
ID=as.factor(c(ones, zeros))
N.obs.train.k.lmFE=rep(N.obs.k, times=2)
zeros=rep(0, times=15)
ones=rep(1, times=15)
ID=as.factor(c(ones, zeros))
N.obs.train.k.lmFE=rep(N.obs.k, times=2)
accuracy.out.lmFE=c(accuracy.ksets,traditional.accuracy.ksets)
accuracy.df.lmFE=data.frame(N.obs.train.k, ID, accuracy.out)
accuracy.lm=lm(accuracy.out~N.obs.train.k, data = accuracy.df)
accuracy.lm=lm(accuracy.ksets~N.obs.k, data = accuracy.df)
(accuracy.lms=summary(accuracy.lm))
accuracy.lmFE=lm(accuracy.out.lmFE~ID*N.obs.train.k.lmFE,
data = accuracy.df.lmFE)
accuracy.plot=ggplot(accuracy.df, aes(x=N.obs.k, y=accuracy.ksets))+
xlab("Observations in Traing Set")+
ylab("Accuracy of Prob.Scoring")+
geom_abline(intercept = as.numeric(coef(accuracy.lm))[[1]],
slope=as.numeric(coef(accuracy.lm))[[2]])+
geom_point()
accuracy.plot
plot(accuracy.lm)
####	MasterCVanalysis.R	 ####
#-------------------------------------------------------------------------#
####	Description:	 ####
# This script will combine the constituent functions, data, and variables needed in order to perform a cross-validation examination of Probabilistic Scoring.
####	Script Dependencies	 ####
# Package Dependencies:
library(ggplot2)
library(boot)
library(reshape)
# Set Working Directory
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis"
setwd(WD)
# Data Dependencies:
# PHQ9 Data
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
# Variable Dependencies:
set.seed(123)
options(warn = -1)
# File Dependencies
## functions:
# Weight Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsWeightCalculations.R")
# Probabilistic Score Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsProbScoreCalc.R")
# Scoring Analysis
source(file="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsScoringAnalysis.R")
boot.sample.train.i=list()
boot.sample.test.i=list()
boot.sample.Nset.i=list()
for(i in 1:n.minus.one+1){
boot.sample.train.i[[i]]=boot.sample.i[[i]][[1]]
boot.sample.test.i[[i]] =boot.sample.i[[i]][[2]]
boot.sample.Nset.i[[i]] =boot.sample.i[[i]][[3]]
}
n.minus.one=14
N.set.arg=seq(from=1248, to=2490, length.out = n.minus.one)
N.set.arg=c(N.set.arg,1247)
for(i in 1:n.minus.one+1){
N.set.arg[i]=floor(N.set.arg[i])
}
boot.sample.train.i=list()
boot.sample.test.i=list()
boot.sample.Nset.i=list()
for(i in 1:n.minus.one+1){
boot.sample.train.i[[i]]=boot.sample.i[[i]][[1]]
boot.sample.test.i[[i]] =boot.sample.i[[i]][[2]]
boot.sample.Nset.i[[i]] =boot.sample.i[[i]][[3]]
}
# i in 1:5
boot.weights.i=list()
for(i in 1:n.minus.one+1){
# j in 1:N.set.arg[i]
boot.weights.i.j=list()
for(j in 1:N.set.arg[i]){
boot.weights.i.j[[j]]=ReformatWeights(PCVeval_overQnum(boot.sample.train.i[[i]][[j]]))
for(k in 1:3){
boot.weights.i.j[[j]][[k]]=round(boot.weights.i.j[[j]][[k]], digits = 4)
}
}
boot.weights.i[[i]]=boot.weights.i.j
}
save(boot.weights.i, file = "/Users/lee/Desktop/BootWeights15.Rdata")
weight.out.i=list()
for(i in 1:50){
weight.out.i.k=list()
for(k in 1:3){
weight.out.i.k.j=list()
for(j in 1:4){
weight.out.i.k.j.l=list()
for(l in 1:9){
weight.out.i.k.j.l.h=c()
for(h in 1:N.set.arg[i]){
weight.out.i.k.j.l.h=append(weight.out.i.k.j.l.h,
boot.weights.i[[i]][[h]][[k]][l,j])
}
weight.out.i.k.j.l[[l]]=weight.out.i.k.j.l.h
}
weight.out.i.k.j[[j]]=weight.out.i.k.j.l
}
weight.out.i.k[[k]]=weight.out.i.k.j
}
weight.out.i[[i]]=weight.out.i.k
}
View(boot.weights.i)
weight.out.i=weight.out.i[[-1]]
weight.out.i=list()
for(i in 1:n.minus.one+1){
weight.out.i.k=list()
for(k in 1:3){
weight.out.i.k.j=list()
for(j in 1:4){
weight.out.i.k.j.l=list()
for(l in 1:9){
weight.out.i.k.j.l.h=c()
for(h in 1:N.set.arg[i]){
weight.out.i.k.j.l.h=append(weight.out.i.k.j.l.h,
boot.weights.i[[i]][[h]][[k]][l,j])
}
weight.out.i.k.j.l[[l]]=weight.out.i.k.j.l.h
}
weight.out.i.k.j[[j]]=weight.out.i.k.j.l
}
weight.out.i.k[[k]]=weight.out.i.k.j
}
weight.out.i[[i]]=weight.out.i.k
}
var.weight.i=list()
for(i in 1:50){
var.weight.i.j=list()
for(j in 1:3){
var.weight.i.j.k=list()
for(k in 1:4){
var.weight.i.j.k.l=c()
for(l in 1:9){
var.weight.i.j.k.l[l]=var(weight.out.i[[i]][[j]][[k]][[l]])
}
var.weight.i.j.k[[k]]=var.weight.i.j.k.l
}
var.weight.i.j[[j]]=var.weight.i.j.k
}
var.weight.i[[i]]=var.weight.i.j
}
var.weight.i=list()
for(i in 1:n.minus.one+1){
var.weight.i.j=list()
for(j in 1:3){
var.weight.i.j.k=list()
for(k in 1:4){
var.weight.i.j.k.l=c()
for(l in 1:9){
var.weight.i.j.k.l[l]=var(weight.out.i[[i]][[j]][[k]][[l]])
}
var.weight.i.j.k[[k]]=var.weight.i.j.k.l
}
var.weight.i.j[[j]]=var.weight.i.j.k
}
var.weight.i[[i]]=var.weight.i.j
}
# X.Class.Response.Qnum
X.1.2.3=c()
X.1.2.6=c()
X.1.2.9=c()
X.1.4.3=c()
X.1.4.6=c()
X.1.4.9=c()
X.2.2.3=c()
X.2.2.6=c()
X.2.2.9=c()
X.2.4.3=c()
X.2.4.6=c()
X.2.4.9=c()
X.3.2.3=c()
X.3.2.6=c()
X.3.2.9=c()
X.3.4.3=c()
X.3.4.6=c()
X.3.4.9=c()
# var.weight.i[[Nsetval]][[class]][[response]][[qnumber]]
for(i in 1:n.minus.one+1){
X.1.2.3[i]=var.weight.i[[i]][[1]][[2]][3]
X.1.2.6[i]=var.weight.i[[i]][[1]][[2]][6]
X.1.2.9[i]=var.weight.i[[i]][[1]][[2]][9]
X.1.4.3[i]=var.weight.i[[i]][[1]][[4]][3]
X.1.4.6[i]=var.weight.i[[i]][[1]][[4]][6]
X.1.4.9[i]=var.weight.i[[i]][[1]][[4]][9]
X.2.2.3[i]=var.weight.i[[i]][[2]][[2]][3]
X.2.2.6[i]=var.weight.i[[i]][[2]][[2]][6]
X.2.2.9[i]=var.weight.i[[i]][[2]][[2]][9]
X.2.4.3[i]=var.weight.i[[i]][[2]][[4]][3]
X.2.4.6[i]=var.weight.i[[i]][[2]][[4]][6]
X.2.4.9[i]=var.weight.i[[i]][[2]][[4]][9]
X.3.2.3[i]=var.weight.i[[i]][[3]][[2]][3]
X.3.2.6[i]=var.weight.i[[i]][[3]][[2]][6]
X.3.2.9[i]=var.weight.i[[i]][[3]][[2]][9]
X.3.4.3[i]=var.weight.i[[i]][[3]][[4]][3]
X.3.4.6[i]=var.weight.i[[i]][[3]][[4]][6]
X.3.4.9[i]=var.weight.i[[i]][[3]][[4]][9]
}
df.var.X=data.frame(rbind(X.1.2.3,
X.1.2.6,
X.1.2.9,
X.1.4.3,
X.1.4.6,
X.1.4.9,
X.2.2.3,
X.2.2.6,
X.2.2.9,
X.2.4.3,
X.2.4.6,
X.2.4.9,
X.3.2.3,
X.3.2.6,
X.3.2.9,
X.3.4.3,
X.3.4.6,
X.3.4.9))
View(df.var.X)
colnames(df.var.X)=N.set.arg
class.id=c(rep("1", times=6),
rep("2", times=6),
rep("3", times=6))
response=rep( c(rep("2", times=3) , rep("4", times=3)), times=3)
qnum=rep(c("3", "6", "9"), times=6)
df.var.X$class.id=class.id
df.var.X$response=response
df.var.X$qnum=qnum
df.var.re=melt(df.var.X, id=c("class.id","response","qnum"))
View(df.var.re)
df.var.re=df.var.re[-1:18,]
df.var.re=df.var.re[-c(1:18),]
p=ggplot(df.var.re, aes(x=train.count, y=variation))+
geom_point(aes(shape=class.id, color=qnum))+
geom_line()
p
colnames(df.var.re)=c("class.id", "response", "qnum", "train.count", "variation")
p=ggplot(df.var.re, aes(x=train.count, y=variation))+
geom_point(aes(shape=class.id, color=qnum))+
geom_line()
p
p=ggplot(df.var.re, aes(x=train.count, y=variation))+
geom_point(aes(shape=class.id, color=qnum))+
geom_point()
p
p=ggplot(df.var.re, aes(x=train.count, y=variation))+
geom_point(aes(shape=class.id, color=qnum))+
p
p=ggplot(df.var.re, aes(x=train.count, y=variation))+
geom_point(aes(shape=class.id, color=qnum))+
p
p=ggplot(df.var.re, aes(x=train.count, y=variation))+
geom_point(aes(shape=class.id, color=qnum))
p
accuracy.ksets=c()
traditional.accuracy.ksets=c()
N.obs.k=c()
#lower.loop.limit=1225
#upper.loop.limit=1275
n.minus.one=24
N.set.arg=seq(from=1248, to=2490, length.out = n.minus.one)
N.set.arg=c(N.set.arg,1247)
for(i in 1:n.minus.one+1){
N.set.arg[i]=floor(N.set.arg[i])
}
boot.sample.i=list()
for(i in 1:n.minus.one+1){
boot.sample.i[[i]]=CVsplit(phq9, N.set.arg[i])
}
for(k in 1:n.minus.one+1){
k.setVal=N.set.arg[k]
k.index=k
####	Divide Data into K CV data sets
#CVk.dat=CVsplit(phq9, k.setVal)
CVk.dat=boot.sample.i[[k.index]]
Number.k.obs=CVk.dat[[3]]
####  Initialized Empty Variables
CVk_j.train=list()
CVk_j.test=list()
CVk_j.train.weights=list()
CVk_j.data.accuracy=c()
CVk_j.data.accuracy.traditional=c()
for(j in 1:k.setVal){
CVk_j.train[[j]]=CVk.dat[[1]][[j]]
CVk_j.test[[j]]=CVk.dat[[2]][[j]]
CVk_j.probClasses=c()
CVk_j.probClasses.Convg=list()
### Calculate data weights
CVk_j.train.weights[[j]]=ReformatWeights(PCVeval_overQnum(CVk_j.train[[j]]))
for(i in 1:3){
CVk_j.train.weights[[j]][[i]]=round(CVk_j.train.weights[[j]][[i]], digits = 4)
}
###  Calculate CVk-j probabilistic outcomes
CVk_j.probSequences=EvalSeqSubject(CVk_j.train.weights[[j]], CVk_j.test[[j]], 1)
for(i in 1:Number.k.obs){
CVk_j.probClasses.Convg[[i]]=convg(CVk_j.probSequences[[i]], 0.75)
}
for(i in 1:Number.k.obs){
CVk_j.probClasses[i]=CVk_j.probClasses.Convg[[i]][[3]]
}
####  Calculate Accuracy of probablistic classes
CVk_j.data.accuracy[j]=length(which(CVk_j.probClasses==CVk_j.test[[j]]$SupOutNum))/Number.k.obs
####  Calculate Accuracy of traditional Classes
CVk_j.data.accuracy.traditional[j]=length(which(CVk_j.test[[j]]$sumClassNum==CVk_j.test[[j]]$SupOutNum))/Number.k.obs
}
####  Output Accuracy Values
CVk.accuracy=mean(CVk_j.data.accuracy)
accuracy.ksets[k.index]=CVk.accuracy
CVk.accuracy.traditional=mean(CVk_j.data.accuracy.traditional)
traditional.accuracy.ksets[k.index]=CVk.accuracy.traditional
N.obs.k[k.index]=Number.k.obs*(k.setVal-1)
}
N.obs.k=c()
for(k in 1:n.minus.one+1){
N.obs.k[k]=length(boot.sample.i[[k]][[1]])
}
accuracy.df=data.frame(N.obs.k, accuracy.ksets)
accuracy.plot=ggplot(accuracy.df, aes(x=N.obs.k, y=accuracy.ksets))+
xlab("Observations in Traing Set")+
ylab("Accuracy of Prob.Scoring")+
geom_abline(intercept = as.numeric(coef(accuracy.lm))[[1]],
slope=as.numeric(coef(accuracy.lm))[[2]])+
geom_point()
accuracy.plot
View(accuracy.plot)
accuracy.lm=lm(accuracy.ksets~N.obs.k, data = accuracy.df)
(accuracy.lms=summary(accuracy.lm))
