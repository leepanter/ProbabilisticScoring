# (percent.indext.9s=length(index.9s)/2495)
# (percent.indext.9s2=length(index.9s)/(2495*3))
#
# (percent.indext.11s=length(index.11s)/2495)
# (percent.indext.11s2=length(index.11s)/(2495*3))
#
#
#
# # Integrating data that is the next furthests value away: 5,12
# index.5s =which(dat.in$qTot==5)
# index.12s =which(dat.in$qTot==12)
#
# (percent.indext.5s=length(index.5s)/2495)
# (percent.indext.5s2=length(index.5s)/(2495*4))
#
# (percent.indext.12s=length(index.12s)/2495)
# (percent.indext.12s2=length(index.12s)/(2495*4))
#
sum.val=c(5,6,7,8,9,10,11,12)
perc.index.val=c(round( length(which(dat.in$qTot==5))/2495,digits=4),
round( length(which(dat.in$qTot==6))/2495,digits=4),
round( length(which(dat.in$qTot==7))/2495,digits=4),
round( length(which(dat.in$qTot==8))/2495,digits=4),
round( length(which(dat.in$qTot==9))/2495,digits=4),
round(length(which(dat.in$qTot==10))/2495,digits=4),
round(length(which(dat.in$qTot==11))/2495,digits=4),
round(length(which(dat.in$qTot==12))/2495,digits=4))
perm.vals=data.frame(sum.val, perc.index.val)
sample.perc=c()
sample.perc[1]=perm.vals$perc.index.val[1]/4
sample.perc[2]=perm.vals$perc.index.val[2]/3
sample.perc[3]=perm.vals$perc.index.val[3]/2
sample.perc[4]=perm.vals$perc.index.val[4]/3
sample.perc[5]=perm.vals$perc.index.val[5]/3
sample.perc[6]=perm.vals$perc.index.val[6]/2
sample.perc[7]=perm.vals$perc.index.val[7]/3
sample.perc[8]=perm.vals$perc.index.val[8]/4
perm.vals$sample.perc= round(sample.perc, digits = 4)
n.obs=c()
n.obs[1]=length(which(dat.in$qTot==5))
n.obs[2]=length(which(dat.in$qTot==6))
n.obs[3]=length(which(dat.in$qTot==7))
n.obs[4]=length(which(dat.in$qTot==8))
n.obs[5]=length(which(dat.in$qTot==9))
n.obs[6]=length(which(dat.in$qTot==10))
n.obs[7]=length(which(dat.in$qTot==11))
n.obs[8]=length(which(dat.in$qTot==12))
perm.vals$n.obs=n.obs
perm.vals$sample.nos=NA_integer_
for(i in 1:8){
perm.vals$sample.nos[i] =
round(perm.vals$sample.perc[i]*perm.vals$n.obs[i], digits = 0)
}
index.sample.5s=sample(which(dat.in$qTot==5) , 2, replace=FALSE)
index.sample.6s=sample(which(dat.in$qTot==6) , 3, replace=FALSE)
index.sample.7s=sample(which(dat.in$qTot==7) , 2, replace=FALSE)
index.sample.8sdown=sample(which(dat.in$qTot==8) , 1, replace=FALSE)
index.sample.8sup=sample(which(dat.in$qTot==8) , 1, replace=FALSE)
index.sample.9sdown=sample(which(dat.in$qTot==9) , 1, replace=FALSE)
index.sample.9sup=sample(which(dat.in$qTot==9) , 1, replace=FALSE)
index.sample.10s=sample(which(dat.in$qTot==10) , 1, replace=FALSE)
index.sample.11s=sample(which(dat.in$qTot==11) , 1, replace=FALSE)
index.sample.12s=sample(which(dat.in$qTot==12) , 1, replace=FALSE)
dat.in$SupOutString=dat.in$sumClassString
dat.in$SupOutNum=dat.in$sumClassNum
dat.in$SupOutNum[index.sample.5s]=ClassNum[2]
dat.in$SupOutString[index.sample.5s]=ClassString[2]
dat.in$SupOutNum[index.sample.6s]=ClassNum[2]
dat.in$SupOutString[index.sample.6s]=ClassString[2]
dat.in$SupOutNum[index.sample.7s]=ClassNum[1]
dat.in$SupOutString[index.sample.7s]=ClassString[1]
dat.in$SupOutNum[index.sample.8sdown]=ClassNum[1]
dat.in$SupOutString[index.sample.8sdown]=ClassString[1]
dat.in$SupOutNum[index.sample.8sup]=ClassNum[3]
dat.in$SupOutString[index.sample.8sup]=ClassString[3]
dat.in$SupOutNum[index.sample.9sdown]=ClassNum[1]
dat.in$SupOutString[index.sample.9sdown]=ClassString[1]
dat.in$SupOutNum[index.sample.9sup]=ClassNum[3]
dat.in$SupOutString[index.sample.9sup]=ClassString[3]
dat.in$SupOutNum[index.sample.10s]=ClassNum[2]
dat.in$SupOutString[index.sample.10s]=ClassString[2]
dat.in$SupOutNum[index.sample.11s]=ClassNum[2]
dat.in$SupOutString[index.sample.11s]=ClassString[2]
dat.in$SupOutNum[index.sample.12s]=ClassNum[2]
dat.in$SupOutString[index.sample.12s]=ClassString[2]
phq9Subset=dat.in
save(phq9Subset, file = "phq9Subset.Rdata")
phq9=phq9Subset
rm(dat.in)
rm(i)
rm(WD)
rm(index.sample.10s)
rm(index.sample.11s)
rm(index.sample.12s)
rm(index.sample.5s)
rm(index.sample.6s)
rm(index.sample.7s)
rm(index.sample.8sdown)
rm(index.sample.8sup)
rm(index.sample.9sdown)
rm(index.sample.9sup)
rm(perm.vals)
rm(phq9Subset)
rm(n.obs)
rm(perc.index.val)
rm(sample.perc)
rm(sum.val)
# functionCVsplit.R
# Description: This script defines the function CVsplit, which takes as arguments:
####	Arguments
# dat.in: Data set to partition
# N.set: Number of sets (total, including test set) into which to partition data
####  Return (Type=list())
# format: list(dat.train.out, dat.test.out, N.obs)
# out.list <-- Contains the elements below
# dat.train.out: a list of training data sets (in order of selection)
# dat.test.out: a list of testing data sets (in order of selection)
# N.obs: a numerical value indicating the number of observations in a training/test set
####  Call:
#  obj = CVsplit(mydat, N)
####	Begin Script	 ####
CVsplit=function(dat.in, N.set){
if(N.set==2496)
{return(list(dat.in))}
else{
N.dat.in.rows=dim(dat.in)[1]
N.dat.in.cols=dim(dat.in)[2]
N.obs=floor(N.dat.in.rows/N.set)
i=1
index.sample.set=1:N.dat.in.rows
index.fixed.set=1:N.dat.in.rows
index.vec=c()
index.list=list()
dat.train.out=list()
dat.test.out=list()
while(i<=N.set){
index.list[[i]]=sample(index.sample.set, N.obs, replace = FALSE)
index.vec=append(index.vec, unique(index.list[[i]]))
dat.test.out[[i]]=dat.in[index.list[[i]],]
dat.train.out[[i]]=dat.in[-index.list[[i]],]
index.sample.set=index.fixed.set[-index.vec[i]]
i=i+1
}
out.list=list(dat.train.out,
dat.test.out,
N.obs)
return(out.list)
}
}
####	End Script	 ####
####	MasterCVanalysis.R	 ####
#-------------------------------------------------------------------------#
####	Description:	 ####
# This script will combine the constituent functions, data, and variables needed in order to perform a cross-validation examination of Probabilistic Scoring.
####	Script Dependencies	 ####
# Package Dependencies:
# Set Working Directory
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis"
setwd(WD)
# Data Dependencies:
# PHQ9 Data
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
# Variable Dependencies:
set.seed(123)
# File Dependencies
## functions:
# Weight Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsWeightCalculations.R")
# Probabilistic Score Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsProbScoreCalc.R")
full.data=phq9
full.data.weights=ReformatWeights(PCVeval_overQnum(full.data))
for(i in 1:3){
full.data.weights[[i]]=round(full.data.weights[[i]], digits = 4)
}
View(full.data.weights)
full.data.weights[[1]]
full.data.weights[[1]][["A3"]]
full.data.weights[[2]]
full.data.weights[[3]]
####	Example CV Analysis	 ####
CV4.dat=CVsplit(phq9, 4)
CV4.dat
View(CV4.dat)
CV4.sequences=EvalSeqData(CV4.dat[[1]], CV4.dat[[2]], 4)
View(CV4.sequences)
View(CV4.sequences)
CV4.sequences[[1]][[1]]
CV4.sequences[[1]][[1]][[1]]
CV4.sequences[[1]][[1]][[1]][[2]]
CV4.sequences[[1]][[1]][[2]]
CV4.sequences[[1]][[1]][[2]]
CV4.sequences[[1]][[1]]
sub.seq.in=CV4.sequences[[1]][[1]]
thresh.in=0.90
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
exceed.thresh.binary=c()
max.seq.val[1]=1/3
if(init.thresh.in < 1/3){exceed.thresh.binary[1]=1}
else{exceed.thresh.binary[1]=0}
if(init.thresh.in < 1/3){exceed.thresh.binary[1]=1}
else{exceed.thresh.binary[1]=0}
exceed.thresh.binary=rep(0, times=0)
sub.seq.in=CV4.sequences[[1]][[1]]
thresh.in=0.90
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
exceed.thresh.binary=rep(0, times=0)
max.seq.val[1]=1/3
if(init.thresh.in < 1/3){exceed.thresh.binary[1]=1}
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
if(init.thresh.in < max(init.sub.seq.in[[i]])){exceed.thresh.binary[i]=1}
}
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
if(init.thresh.in < max(init.sub.seq.in[[i]]))
{exceed.thresh.binary[i]=1} else
exceed.thresh.binary[i]=0
}
max.seq.val=c()
exceed.thresh.binary=rep(0, times=9)
max.seq.val[1]=1/3
if(init.thresh.in < 1/3){exceed.thresh.binary[1]=1}
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
if(init.thresh.in < max(init.sub.seq.in[[i]]))
{exceed.thresh.binary[i]=1} else
exceed.thresh.binary[i]=0
}
sub.seq.in=CV4.sequences[[1]][[1]]
thresh.in=0.90
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
exceed.thresh.binary=rep(0, times=1)
max.seq.val[1]=1/3
if(init.thresh.in < 1/3){exceed.thresh.binary[1]=1}
sub.seq.in=CV4.sequences[[1]][[1]]
thresh.in=0.90
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
exceed.thresh.binary=c()
max.seq.val[1]=1/3
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
if(init.thresh.in < max(init.sub.seq.in[[i]]))
{exceed.thresh.binary[i]=1} else
exceed.thresh.binary[i]=0
}
j=1
while(max.seq.val[j] < init.thresh.in){
exceed.thresh.binary[j]=0
j=j+1
}
sub.seq.in=CV4.sequences[[1]][[1]]
thresh.in=0.90
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
exceed.thresh.binary=c()
max.seq.val[1]=1/3
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
# if(init.thresh.in < max(init.sub.seq.in[[i]]))
#   {exceed.thresh.binary[i]=1} else
#     exceed.thresh.binary[i]=0
}
j=1
while(max.seq.val[j] < init.thresh.in){
exceed.thresh.binary[j]=0
j=j+1
}
max.seq.val[1]=1/3
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
# if(init.thresh.in < max(init.sub.seq.in[[i]]))
#   {exceed.thresh.binary[i]=1} else
#     exceed.thresh.binary[i]=0
}
j=1
while(max.seq.val[j] < init.thresh.in){
exceed.thresh.binary[j]=0
j=j+1
}
max.seq.val[1]=1/3
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
# if(init.thresh.in < max(init.sub.seq.in[[i]]))
#   {exceed.thresh.binary[i]=1} else
#     exceed.thresh.binary[i]=0
}
j=1
while(max.seq.val[j] < init.thresh.in){
exceed.thresh.binary[j]=0
j=j+1
}
index.max=which(init.sub.seq.in==max.seq.val[j+1])
index.max=which(init.sub.seq.in[[j+1]]==max.seq.val[j+1])
(index.max=which(init.sub.seq.in[[j+1]]==max.seq.val[j+1]))
if(j<9 | max.seq.val[9] >= init.thresh.in){
index.max=which(init.sub.seq.in[[j+1]]==max.seq.val[j+1])
out.result=list(j+1, max.seq.val[j+1], index.max)
return(list())
}
if(j<9 | max.seq.val[9] >= init.thresh.in){
index.max=which(init.sub.seq.in[[j+1]]==max.seq.val[j+1])
out.result=list(j+1, max.seq.val[j+1], index.max)
return(list())
}
out.result=list(j+1, max.seq.val[j+1], index.max)
View(out.result)
convg=function(sub.seq.in, thresh.in){
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
exceed.thresh.binary=c()
max.seq.val[1]=1/3
j=1
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
}
while(max.seq.val[j] < init.thresh.in){
exceed.thresh.binary[j]=0
j=j+1
}
if(j<9 | max.seq.val[9] >= init.thresh.in){
index.max=which(init.sub.seq.in[[j]]==max.seq.val[j])
out.result=list(j, max.seq.val[j], index.max)
return(list(out.result))
}
}
CV4.sequences[[1]]
CV4.convg.90[[i]]=convg(CV4.sequences[[1]][[i]], 0.90)
for(i in 1:623){
CV4.convg.90[[i]]=convg(CV4.sequences[[1]][[i]], 0.90)
}
CV4.convg.90=list()
for(i in 1:623){
CV4.convg.90[[i]]=convg(CV4.sequences[[1]][[i]], 0.90)
}
sub.seq.in=CV4.sequences[[1]][[1]]
thresh.in=0.90
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
exceed.thresh.binary=c()
max.seq.val[1]=1/3
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
}
index.j=which(max.seq.val >= init.thresh.in)
index.j=min(which(max.seq.val >= init.thresh.in))
if(index.j<9 | max.seq.val[9] >= init.thresh.in){
index.max=which(init.sub.seq.in[[index.j]]==max.seq.val[index.j])
out.result=list(index.j, max.seq.val[index.j], index.max)
return(out.result)
} else
return(list(NA, NA, NA))
sub.seq.in=CV4.sequences[[1]][[1]]
thresh.in=0.90
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
exceed.thresh.binary=c()
max.seq.val[1]=1/3
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
}
index.j=min(which(max.seq.val >= init.thresh.in))
if(index.j<9 | max.seq.val[9] >= init.thresh.in){
index.max=which(init.sub.seq.in[[index.j]]==max.seq.val[index.j])
out.result=list(index.j, max.seq.val[index.j], index.max)
return(out.result)
} else return(list(NA, NA, NA))
View(out.result)
convg=function(sub.seq.in, thresh.in){
init.sub.seq.in=sub.seq.in
init.thresh.in=thresh.in
max.seq.val=c()
max.seq.val[1]=1/3
for(i in 2:9){
max.seq.val[i]=max(init.sub.seq.in[[i]])
}
index.j=min(which(max.seq.val >= init.thresh.in))
if(index.j<9 | max.seq.val[9] >= init.thresh.in){
index.max=which(init.sub.seq.in[[index.j]]==max.seq.val[index.j])
out.result=list(index.j, max.seq.val[index.j], index.max)
return(out.result)
} else return(list(NA, NA, NA))
}
CV4.convg.90=list()
####	MasterCVanalysis.R	 ####
#-------------------------------------------------------------------------#
####	Description:	 ####
# This script will combine the constituent functions, data, and variables needed in order to perform a cross-validation examination of Probabilistic Scoring.
####	Script Dependencies	 ####
# Package Dependencies:
# Set Working Directory
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis"
setwd(WD)
# Data Dependencies:
# PHQ9 Data
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
# Variable Dependencies:
set.seed(123)
# File Dependencies
## functions:
# Weight Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsWeightCalculations.R")
# Probabilistic Score Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsProbScoreCalc.R")
#-------------------------------------------------------------------------#
####	Begin Script	 ####
#-------------------------------------------------------------------------#
#### full data weight calculations	 ####
full.data=phq9
full.data.weights=ReformatWeights(PCVeval_overQnum(full.data))
for(i in 1:3){
full.data.weights[[i]]=round(full.data.weights[[i]], digits = 4)
}
####	Example of calculation of Probabilistic Weights	 ####
CV4.dat=CVsplit(phq9, 4)
CV4.sequences=EvalSeqData(CV4.dat[[1]], CV4.dat[[2]], 4)
CV4.convg.90=list()
for(i in 1:623){
CV4.convg.90[[i]]=convg(CV4.sequences[[1]][[i]], 0.90)
}
View(CV4.convg.90)
warnings()
options(warn = -1)
####	MasterCVanalysis.R	 ####
#-------------------------------------------------------------------------#
####	Description:	 ####
# This script will combine the constituent functions, data, and variables needed in order to perform a cross-validation examination of Probabilistic Scoring.
####	Script Dependencies	 ####
# Package Dependencies:
# Set Working Directory
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis"
setwd(WD)
# Data Dependencies:
# PHQ9 Data
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
# Variable Dependencies:
set.seed(123)
options(warn = -1)
# File Dependencies
## functions:
# Weight Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsWeightCalculations.R")
# Probabilistic Score Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsProbScoreCalc.R")
#-------------------------------------------------------------------------#
####	Begin Script	 ####
#-------------------------------------------------------------------------#
#### full data weight calculations	 ####
full.data=phq9
full.data.weights=ReformatWeights(PCVeval_overQnum(full.data))
for(i in 1:3){
full.data.weights[[i]]=round(full.data.weights[[i]], digits = 4)
}
####	Example of calculation of Probabilistic Weights	 ####
CV4.dat=CVsplit(phq9, 4)
CV4.sequences=EvalSeqData(CV4.dat[[1]], CV4.dat[[2]], 4)
CV4.convg.90=list()
for(i in 1:623){
CV4.convg.90[[i]]=convg(CV4.sequences[[1]][[i]], 0.90)
}
####	MasterCVanalysis.R	 ####
#-------------------------------------------------------------------------#
####	Description:	 ####
# This script will combine the constituent functions, data, and variables needed in order to perform a cross-validation examination of Probabilistic Scoring.
####	Script Dependencies	 ####
# Package Dependencies:
# Set Working Directory
WD="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis"
setwd(WD)
# Data Dependencies:
# PHQ9 Data
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/DataManagement/PHQ9/phq9DataSubsetImport.R")
# Variable Dependencies:
set.seed(123)
options(warn = -1)
# File Dependencies
## functions:
# Weight Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsWeightCalculations.R")
# Probabilistic Score Calculations
source(file = "/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsProbScoreCalc.R")
# Scoring Analysis
source(file="/Users/lee/Documents/GitHub/ProbabilisticScoring/Scripts/cvAnalysis/functionsScoringAnalysis.R")
#-------------------------------------------------------------------------#
####	Begin Script	 ####
#-------------------------------------------------------------------------#
#### full data weight calculations	 ####
full.data=phq9
full.data.weights=ReformatWeights(PCVeval_overQnum(full.data))
for(i in 1:3){
full.data.weights[[i]]=round(full.data.weights[[i]], digits = 4)
}
####	Example of calculation of Probabilistic Weights	 ####
CV4.dat=CVsplit(phq9, 4)
CV4.sequences=EvalSeqData(CV4.dat[[1]], CV4.dat[[2]], 4)
CV4.convg.90=list()
for(i in 1:623){
CV4.convg.90[[i]]=convg(CV4.sequences[[1]][[i]], 0.90)
}
View(CV4.convg.90)
