\documentclass[12pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1.0in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={ Final Project Outline},
            pdfauthor={Lee Panter},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{\vspace{3in} Final Project Outline}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Lee Panter}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
    \date{}
    \predate{}\postdate{}
  
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{array}
\usepackage{epsfig}
\usepackage{color}
\usepackage{multirow}
\usepackage{amsrefs}
\usepackage{placeins}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{multicol}
\usepackage{comment}
\usepackage{multirow}
\usepackage{indentfirst}
\usepackage{listings}
\usepackage{setspace}
\usepackage{wrapfig}
\usepackage[right]{lineno}

%\doublespacing
\setlength\parindent{15pt}
\setlength{\parskip}{3mm plus 1mm minus 1mm}

\lstset{frame=tb,
language=R,
aboveskip=3mm,
belowskip=3mm,
showstringspaces=false,
columns=flexible,
numbers=none,
keywordstyle=\color{blue},
numberstyle=\tiny\color{gray},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
breaklines=true,
breakatwhitespace=true,
tabsize=3
}

\begin{document}
\maketitle

\newpage

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
\tableofcontents

\newpage

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{background-context-necessary-for-project}{%
\subsection{Background \& Context necessary for
project}\label{background-context-necessary-for-project}}

\begin{itemize}
\tightlist
\item
  The Patient Health Questionnaire-Nine (PHQ9)

  \begin{itemize}
  \tightlist
  \item
    Self-administered module
  \item
    Can be administer by medical staff
  \item
    Nine questions, answers correspond to the frequency with which
    respondents feel certain feelings
  \item
    Used for screening, monitoring, and grading severity of depressive
    symptoms related to nine criteria outlined by the Diagnostic and
    Statistical Manual of Mental Health Disorders (DSM-IV) {[}1{]}
  \item
    Developed by Dr.~Robert J. Spitzer, Dr.~Janet B.W. Williams,
    Dr.~Kurt Kroenke in 1999 with a grant from Pfizer {[}2{]}
  \item
    Response sets are classified into a discrete set of categories
    corresponding to depression symptom magnitude
  \item
    Three categories corresponding to: ``Not clinically Depressed'',
    ``Sub-threshold Depression'', and ``Major Depression'' will be used
    for this analysis
  \end{itemize}
\end{itemize}

\hypertarget{data}{%
\subsection{Data}\label{data}}

\hypertarget{data-origin}{%
\subsubsection{Data Origin:}\label{data-origin}}

\begin{itemize}
\tightlist
\item
  Federally Qualified Health Research Center in Montana {[}3{]}
\item
  Collected over six month time frame
\item
  Tablet-administered PHQ9s and Quick Diagnostic Panels (QDPs)
\end{itemize}

\hypertarget{data-properties}{%
\subsubsection{Data Properties:}\label{data-properties}}

\begin{itemize}
\tightlist
\item
  Technically a Randomized Control Design based upon assignment of QDPs,
  but observational based upon PHQ9 data
\item
  2495 observations
\item
  286 variables: PHQ9 data, QDP variables, Control variables,
  Demographic variables, Record-keeping (time, date, etc) variables
\item
  De-identified, and left without validation outcome measurement
\item
  No theoretically ``correct'' classification
\item
  Each observation contains integer-value responses (0-3) for the nine
  PHQ9 questions
\item
  No missing data
\item
  Original test was administered sequentially, with all questions being
  asked
\item
  Some respondents had taken the QDP first
\end{itemize}

\hypertarget{classification-methods}{%
\subsection{Classification Methods}\label{classification-methods}}

\begin{itemize}
\tightlist
\item
  Let \(i=1, 2, \ldots, N=2495\) represent a particular observation from
  the PHQ9 data\\
\item
  and let \(q=1, \ 2, \ldots, 9\) represent a specific question within
  each response sequence\\
\item
  each response, to each qustion in an oberservation sequence will be
  denoted \(A_{iq}=a_{iq}\) where the random variable \(A_{iq}\) is
  associated with the outcome \(a_{iq}\)\\
\item
  In referring to an arbitrary (fixed) observation \(I=i^{*}\) we will
  use the shortened notation:

  \begin{itemize}
  \tightlist
  \item
    \(A_{i^{*}q}=A_{q}=k\) where \(k\in \{ 0,\ 1, \ 2, \ 3 \}\)
  \end{itemize}
\end{itemize}

\hypertarget{traditional-classification}{%
\subsubsection{Traditional
Classification}\label{traditional-classification}}

\begin{itemize}
\tightlist
\item
  The traditional classification of observation \(i\) will be denoted:
  \[C_{i}^{TR} \in \mathbf{C}_{i}^{TR}=\left(1_{i}^{TR}, \ 2_{i}^{TR}, \ 3_{i}^{TR} \right)\]
\item
  The sum of an answer set provided in observation \(i\) is represented
  by:

  \begin{itemize}
  \tightlist
  \item
    \(S_{i} = \sum_{q=1}^{9} a_{iq}\)
  \end{itemize}
\item
  the value of \(S_{i}\) is used to assign a traditional classification
  to observation \(i\)
\item
  Depression classification outcomes are distinguished by ``threshold
  values''

  \begin{itemize}
  \tightlist
  \item
    let
    \(\alpha_{1}, \ \alpha_{2} \ \in \left \{ 0, \ldots, 27 \right \}\)
    with \(\alpha_{1} \leq \alpha_{2}\) be threshold values
  \item
    We can define the Traditional Classification outcome sets as
    \(C^{TR}\) for \(C=1,2,3\) using Level sets according to:

    \begin{itemize}
    \tightlist
    \item
      \(1^{TR}=\left \{i \ \Big | \ S_{i} < \alpha_{1} \right \}\)
    \item
      \(2^{TR}=\left \{i \ \Big | \ \alpha_{1} \leq S_{i} < \alpha_{2} \right \}\)
    \item
      \(3^{TR}=\left \{i \ \Big | \ \alpha_{2} \leq S_{i} \right \}\)
    \end{itemize}
  \end{itemize}
\item
  for this analysis, threshold values are: \(\alpha_{1}=7\) and
  \(\alpha_{2}=10\)
\item
  88\% accurate {[}4{]}
\item
  12\% FP/FN causes issues with Clinical Fatigue, patient concern, and
  healthcare system burdens
\item
  Outcomes provide limited information
\item
  Need to take the entire PHQ9 in order to achieve results
\end{itemize}

\hypertarget{probabilistic-classification}{%
\subsubsection{Probabilistic
Classification}\label{probabilistic-classification}}

\begin{itemize}
\tightlist
\item
  Possible benefits:

  \begin{itemize}
  \tightlist
  \item
    Reduced test-taking requirements (early convergence)
  \item
    Increased relatability with other Mental Health disorders, and
    better result integration in general
  \item
    Not dependent on numerical assignments: integer differences of
    outcomes less influential.
  \item
    Training-sample accuracy increase possibility
  \end{itemize}
\item
  The algorithm:

  \begin{itemize}
  \tightlist
  \item
    The probabilistic classification of observation \(i\) will be
    denoted:
    \[C_{i}^{PR} \in \mathbf{C}_{i}^{PR}=(1_{i}^{PR}, \ 2_{i}^{PR}, \ 3_{i}^{PR})\]
  \item
    Given a set of training observations \(\mathbf{S}_{Train}\) of
    length \(|N_{train}|\), we may characterize the probability of
    certain events within that training set:

    \begin{itemize}
    \item
      The probability that a response value of
      \(k \in \left \{ 0, 1, 2, 3 \right \}\) is provided to question
      \(Q=q\) where \(q\in\left \{1,\ldots,9\right \}\) is given by:
      \[P\left(A_{q}=k \right) = \frac{1}{|N_{train}|}\sum_{i=1}^{|N_{train}|} \mathbb{I}\left(A_{iq}=k \right)\]
      where \[\mathbb{I}\left(A_{iq} = k \right)=
      \begin{cases}
        0 &\mbox{if} \quad  a_{iq} \neq k \\
        1 &\mbox{if} \quad  a_{iq}=k \\  
      \end{cases}
      \]
    \item
      The probability that an observation is assigned (via traditional
      classification) into into traditional classification class
      \(C^{TR}=j\) where \(j \in \left \{ 1, \ 2, \ 3 \right \}\) is
      given by:
      \[P\left( C^{TR} = j \right) = \frac{1}{|N_{Train}|} \sum_{i=1}^{|N_{train}|} \mathbb{I}\left(C_{i}^{TR}=j \right)\]
      where \[\mathbb{I}\left(C_{i}^{TR}=j \right)
      \begin{cases}
        0 &\mbox{if} \quad  j \neq c \\
        1 &\mbox{if} \quad  j = c \\  
      \end{cases}
      \]
    \item
      The probability that an observation's response value is
      \(k \in \left \{ 0, 1, 2, 3 \right \}\) in question \(Q=q\) and
      that same observation also has been assigned into traditional
      classification class \(C^{TR}=j\) is given by:
      \[P\left(A_{q} = k \bigcap C^{TR}=j  \right) =  \frac{1}{|j^{TR*}|} \sum_{i \in j^{TR*}} \mathbb{I} \left(A_{iq}=k \right) \]
      where we are defining the level set:
      \[j^{TR*}= \left \{  i \in \mathbf{S}_{Train} \Big | i \in j^{TR} \right \}\]
      for \(j=1,2,3\)

      and the value \(|j^{TR*}|\) represents the number of elements in
      \(j^{TR*}\)
    \end{itemize}
  \end{itemize}
\item
  These probabilities allow us to define a weight parameter
  corresponding to each 108 distinct combination of

  \begin{itemize}
  \tightlist
  \item
    question number: \(Q=q \in \left \{ 1, \ 2, \ldots, 9 \right \}\)
  \item
    response value: \(A_{q} = k \in \left \{ 0, 1, 2, 3 \right \}\)
  \item
    traditional classification: \(C^{TR} = j\) \begin{align*}
     \mathbf{W}_{A_{q}}^{j^{TR}} &= \frac{P\left(A_{q}=k \ \Big | \ C^{TR}= j  \right) }{P\left(A_{q}=k \right) } \tag{EQ-XX} \\[0.5em]
     &= \frac{ P\left(A_{q}=k \ \bigcap \ C^{TR}= j \right) }{P\left(A_{q}=k \right) P\left( C^{TR}= j \right)} \\[0.5em]
     &= \frac{\frac{1}{|j^{TR*}|} \sum_{i \in j^{TR*}} \mathbb{I} \left(A_{iq}=k \right)}{\left( \frac{1}{|N_{train}|}\sum_{i=1}^{|N_{train}|} \mathbb{I}\left(A_{iq}=k \right) \right) \left( \frac{1}{|N_{Train}|} \sum_{i=1}^{|N_{train}|} \mathbb{I}\left(C_{i}^{TR}=j \right) \right)  } \\[0.5em]
     &= \left(\frac{|N_{Train}|^{2}}{|j^{TR*}|} \right) \left(\frac{ \sum_{i \in j^{TR*}} \mathbb{I} \left(A_{iq}=k \right)}{\left( \sum_{i=1}^{|N_{train}|} \mathbb{I}\left(A_{iq}=k \right) \right) \left( \sum_{i=1}^{|N_{train}|} \mathbb{I}\left(C_{i}^{TR}=j \right) \right)}   \right)  
     \end{align*}
  \end{itemize}
\item
  Using the weights, we may now calculate the probabilistic
  classification score:

  \begin{itemize}
  \tightlist
  \item
    A pre-specified confidence threshold value \(\gamma \in (0,1)\)
    determines the stopping point of the algoritm which proceeds
    recursively according to the framework:

    \begin{itemize}
    \tightlist
    \item
      Let
      \(\mathbf{C}_{(q)}^{PR}=\left(1_{(q)}^{PR}, \ 2_{(q)}^{PR}, \ 3_{(q)}^{PR} \right)\)
      represent the \(q^{th}\) iteration of the probabilistic
      re-weighting algorithm, for \(q=1, \ldots, 9\)\\
      \begin{align*}
      \left(1_{(0)}^{PR}, \ 2_{(0)}^{PR}, \ 3_{(0)}^{PR} \right) &= \left( \frac{1}{3}, \  \frac{1}{3}, \ \frac{1}{3}\right) \\[0.5em]
      \left(1_{(q+1)}^{PR}, \ 2_{(q+1)}^{PR}, \ 3_{(q+1)}^{PR} \right) &= \frac{\left(1_{(q)}^{PR}W_{A_{q}}^{1^{TR}}, \ 2_{(q)}^{PR}W_{A_{q}}^{2^{TR}}, \ 2_{(q)}^{PR}W_{A_{q}}^{2^{TR}} \right) }{\sum_{j=1}^{3} j_{(q)}^{PR}W_{A_{q}}^{j^{TR}}} \tag{EQ-XX} \label{1.3.2 - 2}
      \end{align*}\\
      for \(q=1, 2, \ldots, 9\)
    \end{itemize}
  \item
    If we define: \[j_{q}^{*}= \underset{j}{max} \  j_{q}^{PR}\] and
    \[q^{*}=\underset{q}{min} \ \left \{q : j^{*}_{q} > \gamma    \right \} \]
    then (provided that \(q^{*}\) exists), the probabilistic scoring
    classification is:
    \[j_{q^{*}}^{*PR}=\underset{j}{max} \ j_{q^{*}}^{PR}\]
  \end{itemize}
\end{itemize}

\hypertarget{consultation-goals-and-deliverables}{%
\subsection{Consultation goals and
deliverables}\label{consultation-goals-and-deliverables}}

\hypertarget{clients-specified-goals}{%
\subsubsection{Client's Specified
Goals:}\label{clients-specified-goals}}

\begin{quote}
``\ldots{}mathematically prove that probabilistic scoring is more
accurate than conventional scoring''
\end{quote}

\begin{quote}
``\ldots{}mathematically prove that probabilistic scoring derived from a
conventional scored validation dataset is essentially as accurate as
using the original validation dataset and therefore still more accurate
than conventional scoring''
\end{quote}

\hypertarget{analysis-goals}{%
\subsubsection{Analysis Goals:}\label{analysis-goals}}

\begin{itemize}
\tightlist
\item
  Compare Probabilistic Scoring accuracy to Conventional Scoring
  accuracy measured against simulated responses generated using
  information in PHQ9 data.
\item
  Determine how accuracy comparisons vary as a function of training
  sample size.
\end{itemize}

\hypertarget{deliverables}{%
\subsubsection{Deliverables:}\label{deliverables}}

\begin{itemize}
\tightlist
\item
  Presentable results. Evidence of outcomes that can be shown to
  potential clients with the purpose of demonstrating the practical
  advantages of Probabilistic Scoring.
\item
  Relationship Diagrams. Visualizations that can be utilized to show
  informational gain when Probabilistic Scoring is implemented.
  Particular interest in relating outcomes to specific question answers.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{model-and-methods}{%
\section{Model and Methods}\label{model-and-methods}}

\hypertarget{quantifying-accuracy}{%
\subsection{Quantifying Accuracy}\label{quantifying-accuracy}}

\begin{itemize}
\tightlist
\item
  Accuracy as a function of model value and validation outcome
  \[\text{Accuracy} = f(\mathbf{y}, \mathbf{\hat{y}}) = \frac{1}{N} \sum_{i=1}^{N}  I\left(y_{i}=\hat{y}_{i} \right)\]

  \begin{itemize}
  \tightlist
  \item
    where \(\mathbf{y}=\left(y_{1}, \ldots, y_{N}\right)\) is the
    validation outcome
  \item
    \(\mathbf{\hat{y}}=\left(\hat{y}_{1},\ldots, \hat{y}_{N} \right)\)
    is the model value
  \item
    \(I\left(y_{i}=\hat{y}_{i} \right)=\begin{cases} 0 &\mbox{if} \quad y_{i} \neq \hat{y}_{i} \\ 1 &\mbox{if} \quad y_{i} = \hat{y}_{i} \\ \end{cases}\)
  \end{itemize}
\item
  Accuracy as a function of model value and \textit{simulated}
  validation outcome
  \[\tilde{\text{Accuracy}} = f(\mathbf{\tilde{y}}, \mathbf{\hat{y}}) = \frac{1}{N} \sum_{i=1}^{N}  I\left(\tilde{y}_{i}=\hat{y}_{i} \right)\]

  \begin{itemize}
  \tightlist
  \item
    where
    \(\mathbf{\tilde{y}}=\left(\tilde{y}_{1}, \ldots, \tilde{y}_{N} \right)\)
    is the simulated validation outcome
  \end{itemize}
\item
  Simulated accuracy calculation can be performed for Traditional and
  Probabilistic Classifications, and then compared: \begin{align*}
  \tilde{Accuracy_{TR}} &\sim \tilde{Accuracy_{PR}} \\[0.5em]
  f\left(\mathbf{\tilde{y}}, \mathbf{\hat{y}}^{TR} \right)  &\sim f\left(\mathbf{\tilde{y}}, \mathbf{\hat{y}}^{PR} \right) \tag{EQ-XX} \label{2.1-1}
  \end{align*}
\item
  This analysis will focus on estimating various values of
  \(\tilde{accuracy}\) using multiple methods of generating values of
  \(\tilde{\mathbf{y}}\)
\end{itemize}

\hypertarget{cross-validation-processing}{%
\subsection{Cross Validation
Processing:}\label{cross-validation-processing}}

\begin{itemize}
\tightlist
\item
  Estimating \(\tilde{Accuracy}\) using Cross Validation allows us to
  obtain an average-stabilized estimate of both Pscore and traditional
  classifications simultaneously, and to establish the relationship
  between training sample size and accuracy
\item
  For a fixed value of \(K \in \left \{ 1, 2, \ldots, N \right \}\) we
  partition the full data set into \(K\) equal subsets, each of which
  has \(N_{K}\) observations sampled randomly without replacement from
  the original data, where:
  \[N_{K}=\Big \lfloor \frac{N}{K} \Big \rfloor\]
\item
  We now have \(K\) distinct data sets that have been subset from the
  original data, which we will combine into test-train pairs
\item
  There are \(K\) different ways in which \(K-1\) data sets can be
  chosen from \(K\) sets when order does not matter: \begin{align*}
  \binom{k}{k-1} &= \frac{k!}{(k-1)!(k-(k-1))!}\\[0.5em]
  &= \frac{k!}{(k-1)!}\\[0.5em]
  &= k
  \end{align*}
\item
  for each of these \(K\) combinations we create a train-test
  combination by combining the \(K-1\) selected sets to form the
  training set, and the remaining set to form the test set.
\item
  We will denote these train/test pairs
  \[\left(TR, TE \right)^{K}_{j}=\left(TR_{j}^{K}, TE_{j}^{K} \right) \]
  where K will represent the partition number value for the original
  separations and \(j=1, \ldots, K\)
\item
  From the definition of \(N_{K}\), and the fact that each training set
  is a union of \(\left(K-1 \right)\) sets of length \(N_{K}\), we can
  establish a relationship between training set length, i.e.
  \(|TR_{j}^{k}|\) the number of observations in the \(j^{th}\) training
  set and the value of \(K\) from which the original test-train
  partitions were formed:\\
  \[|TR_{j}^{k}|=(K-1)N_{K}=(K-1)\Big \lfloor \frac{N}{K} \Big \rfloor\]
\item
  Similarly, we may define the length of the test set:
  \[|TE_{j}^{k}|=N_{K}=\Big \lfloor \frac{N}{K} \Big \rfloor\]
\item
  noting that:
  \[\Big \lfloor \frac{N}{K} \Big \rfloor \leq \frac{N}{K}\] We have
  \begin{align*}
  |TR_{j}^{K}| + |TE_{j}^{K}| &= (k-1)\Big \lfloor \frac{N}{K} \Big \rfloor + \Big \lfloor \frac{N}{K} \Big \rfloor \\[0.5em]
  &= K \Big \lfloor \frac{N}{K} \Big \rfloor \\[0.5em]
  &\leq K \frac{N}{K} = N
  \end{align*} Implying that observations will be left out of the
  sampling process in the selection of subsets. This is due to the
  definition of the subsample sizes chosen using the floor function
  which is not injective on real valued domains.\\
\item
  We are interested in establishing a relationship between
  \(|TR_{j}^{k}|\) and \(\tilde{accuracy}\), idealistically represented
  by: \[
  \tilde{accuracy}\left( |TE_{j}^{k}|  \right) = \tilde{accuracy}\left( \Big \lfloor \frac{N}{K} \Big \rfloor  \right) \tag{EQ-XX} 
  \] This formula establishes a connection between the value of \(K\)
  and \(\tilde{accuracy}\). Demonstrating that by calculating the value
  of \(\tilde{accuracy}\) at varying the value of \(K\), we may
  establish the relationship between \(\tilde{accuracy}\) and
  \(|TR_{j}^{k}|\) (i.e.~Training Sample Length).
\item
  We can calculate the calculate the classification accuracy for each
  train-test pairing within a specific value of K.
  \[\tilde{accuracy}\left(TR, TE \right)_{j}^{k}= \frac{1}{|TE_{j}^{k}|} \sum_{i=1}^{|TE_{j}^{k}|} I\left(\tilde{y}_{i}=\hat{y}_{i} \right) \]
\item
  and we will use the average of these values to represent the accuracy
  at a particular K-value \begin{align*}
    \tilde{accuracy}\left(TR, TE \right)^{k} &= \tilde{accuracy}_{m}\left(TR, TE \right)_{\bullet}^{k} \\
    &=\frac{1}{K}\sum_{j=1}^{K} \left \{ \tilde{accuracy}\left(TR, TE \right)_{j}^{k}\right \} \\
    &=  \frac{1}{K}\sum_{j=1}^{K} \left \{ \frac{1}{|TE_{j}^{k}|} \sum_{i=1}^{|TE_{j}^{k}|} I\left(\tilde{y}_{i}=\hat{y}_{i} \right) \right \}
  \end{align*}
\item
  This process can be applied to Traditional and Probabilistic Scoring
  methods: \begin{align*}
    \tilde{accuracy}_{m}\left(TR, TE \right)^{k} &= \frac{1}{K}\sum_{j=1}^{K} \left \{ \tilde{accuracy}_{m}\left(TR, TE \right)_{j}^{k}\right \} \\
    &=  \frac{1}{K}\sum_{j=1}^{K} \left \{ \frac{1}{|TE_{j}^{k}|} \sum_{i=1}^{|TE_{j}^{k}|} I\left(\tilde{y}_{i}=\hat{y}_{i}^{m} \right) \right \}
  \end{align*} where \(m\in\left \{ Pscore, \ Tscore \right \}\),
  \(\hat{y}^{Pscore}\) is a Probabilistic Scoring generated outcome, and
  \(\hat{y}^{Tscore}\) is a Traditional Scoring generate outcome
\item
  It will also be applied to a multitude of different simulated
  validation outcomes \begin{eqnarray*}
    \tilde{accuracy}_{m}^{h}\left(TR, TE \right)^{k} &= \frac{1}{K}\sum_{j=1}^{K} \left \{ \tilde{accuracy}_{m}^{h}\left(TR, TE \right)_{j}^{k}\right \} \\
    &=  \frac{1}{K}\sum_{j=1}^{K} \left \{ \frac{1}{|TE_{j}^{k}|} \sum_{i=1}^{|TE_{j}^{k}|} I\left(\tilde{y}_{i}^{h}=\hat{y}_{i}^{m} \right) \right \}
  \end{eqnarray*} where the values of \(h\) will be outlined in
  \textbf{Section XX}.
\item
  Since notation is obviously cumbersome, indices displayed will be
  limited only to those relevant.
\item
  \textbf{Figure XX}
\item
  \includegraphics{/Users/lee/Documents/GitHub/ProbabilisticScoring/WriteUps/Outline/KvsTrainlen.jpeg}
\item
  \textbf{Figure XX:} Training and Test set observation counts vs K
\item
  We see that the possible training set observation counts using the CV
  method outlined above on the data provided range between 1247 and 2492
  observations.
\item
  The figure also shows that for K-values greater than 1248, test set
  sizes are confined to one.
\item
  Training set sizes were selected for analysis by sampling 50 different
  values of K from k=5 to k=2490.
\item
  Plots of comparing accuracies in the form of \eqref{2.1-1} are shown
  for each value of K selected as the value of training set length
  corresponding to K increases
\item
  It was assumed that subsets taken from the data which were sampled
  randomly without replacement are at least partially representative of
  the population as a whole.
\end{itemize}

\hypertarget{optimal-convergence-criterion}{%
\subsection{Optimal Convergence
Criterion}\label{optimal-convergence-criterion}}

\begin{itemize}
\tightlist
\item
  The Pscore algorithm requires the specification of a confidence level
  for termination.
\item
  For the purposes of this analysis, a confidence level of 0.75 was
  chosen.
\item
  This value optimized probabilistic scoring classification accuracy of
  the first simulated validation outcome (see below) when the Pscoring
  weights were trained on the full data set.
\end{itemize}

\hypertarget{simulated-validation-outcomes}{%
\subsection{Simulated Validation
Outcomes}\label{simulated-validation-outcomes}}

\hypertarget{inferential-simulations}{%
\subsubsection{Inferential Simulations}\label{inferential-simulations}}

\begin{itemize}
\tightlist
\item
  Theoretical assumptions made:

  \begin{itemize}
  \tightlist
  \item
    Depression Classifications are a hierarchy, so outcomes for group 1
    are lower than group 2,\ldots{}etc
  \item
    Within each class there is a spectrum of conditions, and transitions
    between classes are essentially continuous.
  \item
    The 12 percent misclassification is due to the traditional scoring
    algorithm mis-classifying observations into a proximal class. Group
    1 into group 2, group 3 into group 2 or group 2 into either group 1
    or 2.
  \end{itemize}
\item
  Practical implementations of quantity switched related to:

  \begin{itemize}
  \tightlist
  \item
    traditional sum statistic

    \begin{itemize}
    \tightlist
    \item
      Let \(\mathbb{S}^{PR}_{T}=\left \{ i\ \Big | \ S_{i}=T \right \}\)
      for \(i=1,\ldots, N\) and \(T=0, 1,\ldots, 27\) where
      \(S_{i} = \sum_{q=1}^{9} a_{q}\)
    \item
      Then the number of observations with the same traditional
      sum-score (\(S_{i}\)) is the value: \(|\mathbb{S}^{PR}_{T}|\)
    \end{itemize}
  \item
    Distance from a threshold value. Meaning that observations which are
    closer to a threshold value are more likely to be mis-classified
    (switched)

    \begin{itemize}
    \tightlist
    \item
      If we suppose that
      \(\alpha_{1} \leq \alpha_{2} \in \ \left \{ 0,1,\ldots, 27 \right \}\)
      are threshold values. The distance to the nearest threshold value
      of an observation \(i\) that is classified into traditional sum
      value \(S_{i}\) is:
      \[D_{i} = \underset{k=1,2}{min}\left \{ \Big | \alpha_{k}-S_{i}   \Big | \right \}\]
    \end{itemize}
  \end{itemize}
\item
  The final probability of a traditional classification being altered in
  its representation in the simulated outcome data set:

  \begin{itemize}
  \tightlist
  \item
    \(P\left(j_{i}^{TR} \neq \tilde{j}_{i} \right) \propto \frac{|\mathbb{S}^{PR}_{T}|}{D_{i}}\)
  \item
    Proportionality constants were chosen so that the total difference
    between Traditional Scoring classification and simulated outcome was
    12\%
  \item
    Specific values of \(P\left(j_{i}^{TR} \neq \tilde{j}_{i} \right)\)
    that were used for this analysis are displayed in \textbf{Table XX}
  \end{itemize}
\end{itemize}

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
Trad Sum & Orig Class & SimClass & $D_{\alpha_{1}}$ & $D_{\alpha_{2}}$ & $|\mathbb{S}_{T}^{PR}|$ & NO Flip & Prop Const & \% Total Data \\
\hline
\hline
5 & 1 & 2 & 2 & 5 & 149 & 42 & 0.282 & 0.017 \\
\hline
6 & 1 & 2 & 1 & 4 & 137 & 63 & 0.460 & 0.025 \\
\hline
7 & 2 & 1 & 0 & 3 & 108 & 42 & 0.389 & 0.017 \\
\hline
8 & 2 & 1 & 1 & 2 & 115 & 19 & 0.165 & 0.008 \\
\hline
8 & 2 & 3 & 1 & 2 & 115 & 21 & 0.183 & 0.008 \\
\hline
9 & 2 & 1 & 2 & 1 & 134 & 16 & 0.119 & 0.006 \\
\hline
9 & 2 & 3 & 2 & 1 & 134 & 21 & 0.157 & 0.008 \\
\hline
10 & 3 & 2 & 3 & 0 & 72 & 21 & 0.292 & 0.008 \\
\hline
11 & 3 & 2 & 4 & 1 & 73 & 21 & 0.288 & 0.008 \\
\hline
12 & 3 & 2 & 5 & 2 & 77 & 21 & 0.273 & 0.008 \\
\hline
 &  &  &  &  &  &  & SUM $\rightarrow$ & 0.113 \\
\hline
\end{tabular}
\end{center}

\begin{itemize}
\tightlist
\item
  \textbf{Figure 2:}
\item
  \includegraphics{/Users/lee/Documents/GitHub/ProbabilisticScoring/WriteUps/Outline/ClassFlips.jpeg}
\item
  \textbf{Figure 2 Caption:} Figure depicts observational distributions
  as classified by traditional methods, and how the first simulated
  validation outcome induced change
\item
  Simulated validation outcomes generated using this method depended
  only on information relevant to the observation for which the outcome
  was being simulated
\item
  Pairing of simulated validation outcomes performed with full-data
\item
  Accuracy comparisons of Probabilistic Scoring and Traditional Scoring
  classifications were obtained on 100 different values of K using the
  CV algorithm previously outlined.
\item
  The simulated outcome generated using this method was implemented in
  the process to obtain the optimal convergence confidence level in
  \textbf{Section XX}
\end{itemize}

\hypertarget{probabilistic-outcome-simulations}{%
\subsubsection{Probabilistic Outcome
Simulations}\label{probabilistic-outcome-simulations}}

\begin{itemize}
\tightlist
\item
  Motivating Principle: The Pscoring algorithm incorporates more
  information contained in the data than anything else, therefore it
  should generate the most appropriate estimates
\item
  Motivating Principle: The Pscoring algorithm can estimate multiple
  amounts of inherently different estimates for the same observations
  based upon different training sets.
\item
  The process:

  \begin{itemize}
  \tightlist
  \item
    Separate data into K-CV sets, and combine into train-test pairings
    as before in the CV analysis \[(TR, TE)_{j}^{K}\] where
    \(j =1, \ldots, K\)
  \item
    For each training set, calculate the corresponding set of Pscore
    weights
    \[TR_{j}^{K} \ \rightarrow \text{equation} \ \eqref{1.3.2-1} \ \rightarrow \  W_{AQj}^{C}\]

    \begin{itemize}
    \tightlist
    \item
      K train-test pairs means there will be K distinct estimates of the
      training weights
    \end{itemize}
  \item
    Calculate a representative weight set for the value of K by
    averaging over the K weight values
    \[W_{AQk}^{C}=\frac{1}{K}\sum_{j=1}^{K} W_{AQj}^{C}\]
  \item
    For each of the K test sets use the calculated, representative
    weights to Probabilistically Classify a corresponding set of
    \textit{simulated validation outcomes}
    \[\left(W_{AQk}^{C}, TE_{j}^{k}\right)  \ \rightarrow \ \text{equation} \ \eqref{1.3.2 - 2} \ \rightarrow \   \tilde{y}_{j}^2{k}\]
  \item
    The outcomes generated using this method depend on information
    obtained from a training set used to generate Pscore weights which
    were used in its classifications.\\
  \item
    Each simulated outcome will therefore be paired with data that was
    simulated using the same set of information. (i.e.~categorized using
    the same training data).
  \item
    The values of the simulated outcome specific to training sample
    within each K value are then substituted into the CV algorithm for
    \(\tilde{y}^{h}\) \begin{eqnarray*}
      \tilde{accuracy}_{m}^{h}\left(TR, TE \right)^{k} &= \frac{1}{K}\sum_{j=1}^{K} \left \{\tilde{accuracy}_{m}^{h} \left(TR, TE)_{j}^{k}   \right)   \right \} \\
      &= \frac{1}{K}\sum_{j=1}^{K} \left \{ \frac{1}{|TE_{j}^{k}|} \sum_{i=1}^{|TE_{j}^{k}|} \left \{ I\left(\tilde{y}_{i}^{h}=\hat{y}_{i}^{m} \right) \right \}   \right \}
    \end{eqnarray*}
  \end{itemize}
\item
  The method makes the assumption that estimates of average weights are
  stable enough to produce reasonably consistent estimates
\item
  \textbf{Figure 3:}
\item
  \includegraphics{VariancePlot.jpg}
\item
  \textbf{ Figure 3 Caption:} Variance of average weight values for
  several question number/class ID combinations plotted against training
  data count length
\item
  \textbf{Figure 4:}
\item
  \includegraphics{MeanPlot.jpg}
\item
  \textbf{Figure 4 Caption:} Mean value of the average weight estimates
  for several question number/class ID combinations plotted against
  training data count length
\item
  Stability of the average estimate value, as training sample increases,
  in combination with a dramatic decrease in variance as training sample
  size increases are indications that the average weight values are
  capable of producing stable outcome estimates
\end{itemize}

\hypertarget{unsupervised-learning-classifications}{%
\subsubsection{Unsupervised Learning
Classifications}\label{unsupervised-learning-classifications}}

\begin{itemize}
\tightlist
\item
  Using unsupervised learning techniques to deduce trends in the PHQ9 is
  a powerful tool
\item
  The general algorithm we will exploit in the following fitting
  processes

  \begin{itemize}
  \tightlist
  \item
    Use an unsupervised method to cluster PHQ9 observations, preferably
    make as few assumptions as possible
  \item
    Use the hierarchical aspects of the outcome classes (the fact that
    Depression classifications increase in magnitude) to group clusters
    into three clusters representing a simulated outcome classification
    for the observations contained within the cluster.
  \item
    Input the simulated outcome classifications into the CV algorithm
    and obtain estimates for both Traditional Scoring and Probabilistic
    Scoring accuracies
  \end{itemize}
\end{itemize}

\hypertarget{kmeans-and-hierarchical-clustering}{%
\paragraph{Kmeans and Hierarchical
Clustering}\label{kmeans-and-hierarchical-clustering}}

\begin{itemize}
\tightlist
\item
  Kmeans

  \begin{itemize}
  \tightlist
  \item
    The proper number of clusters in the Kmeans algorithm can be
    determined with the use of an elbow plot
  \item
    \textbf{Figure 4:}
  \item
    \includegraphics{ElbowPlot.jpeg}
  \item
    \textbf{Figure 4 Caption:} A plot depicting the total within sum of
    squares vs the number of clusters chosen for the algorithm
  \item
    The elbow plot demonstrates that the data has a natural tendency to
    form three clusters, and therefore, no intermediate mapping is
    necessary.
  \end{itemize}
\item
  Hierarchical Clustering

  \begin{itemize}
  \tightlist
  \item
    A similar process was completed using two approached to Hierarchical
    clustering
  \item
    The first distinguishes observations based upon Euclidean distance.
    A circular dendogram, with corresponding classifications is
    displayed in \textbf{Figure 5} {[}5{]}
  \item
    \textbf{Figure 5:}
  \item
    \includegraphics[width=0.25\textwidth,height=\textheight]{Hclust1Dend.jpeg}
  \item
    \textbf{Figure 5 Caption:} Circular dendogram with three-category
    classifications
  \item
    The second hierarchical clustering technique distinguishes
    observations based upon Manhattan distance. A circular dendogram,
    with corresponding classifications is displayed in \textbf{Figure 6}
    {[}5{]}
  \item
    \textbf{Figure 6:}
  \item
    \includegraphics[width=0.25\textwidth,height=\textheight]{Hclust2Dend.jpeg}
  \item
    \textbf{Figure 6 Caption:} Circular dendogram with three-category
    classifications
  \end{itemize}
\end{itemize}

\hypertarget{self-organizing-maps}{%
\paragraph{Self Organizing Maps}\label{self-organizing-maps}}

\begin{itemize}
\item
  Self-organizing maps (SOMs) require a pre-specified structure
  (generally a lattice structure) to which observations are clustered
  based upon projected proximity {[}6{]}
\item
  Some advantages of using a SOM over Kmeans, or Hierarchical Clustering
  are:

  \begin{itemize}
  \tightlist
  \item
    Non-linearity. The SOM algorithm has no underlying assumptions
    restricting model structure
  \item
    Topological preservation. SOMs preserve ordering properties found in
    higher dimensions, when mapped to the projection space, therefore
    order (hierarchy) is preserved {[}6{]}
  \item
    Inferential potential. SOM visualization methods are extremely
    useful and meaningful. {[}7{]}
  \end{itemize}
\item
  SOMs have standard pre-processing procedures that dictate
  standardization of observations prior to training.
\item
  Three SOMs lattice structures were fit in this analysis. Each of these
  lattice structures was also fit with both the Euclidean and Manhattan
  metrics that determine the relationship between mapped observations in
  the projection space.
\item
  The SOM lattice Structures implemented are:

  \begin{itemize}
  \tightlist
  \item
    12 X 9 rectangular topology
  \item
    15 X 15 hexagonal topology
  \item
    3 X 9 rectangular topology
  \end{itemize}
\item
  We have chosen to display the most accurate versions of the SOMs
  constructed. We will display those SOMs that have been determined to
  be most accurate (on average) in regards to either probabilistic
  scoring or traditional scoring.
\item
  Further information on the remaining SOMs can be found in
  \textbf{Appendix Section (XX)}
\item
  Plots of each of these mappings are found in \textbf{Figures XX - XX}
  below
\item
  \textbf{Figure 7:}

  \begin{center}
  \includegraphics[width=0.25\textwidth]{KeySom.jpeg}
  \end{center}
\item
  \textbf{Figure 7 Caption}: Color coding key for question magnitude
  representation within each output lattice cluster
\item
  \textbf{Figure 8:}
\item
  \includegraphics[width=0.25\textwidth,height=\textheight]{Som1.jpg}
\item
  \textbf{Figure 8 Caption: Euclidean Norm, 12 X 9-rectangular topology SOM}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{analysis-and-results}{%
\section{Analysis and Results}\label{analysis-and-results}}

\hypertarget{inferential-outcome-simulation}{%
\subsection{Inferential Outcome
Simulation}\label{inferential-outcome-simulation}}

\begin{itemize}
\item
  \textbf{Figure XX:}

  \begin{center}
  \includegraphics[width=0.5\textwidth]{Sup1Graph.jpg}
  \end{center}
\item
  \textbf{Figure XX Caption:} displays estimated accuracy values for
  probabilistic scoring classifications and traditional scoring
  classifications across 50 values of training set definitions. Also
  plotted are Linear Regression trend lines for each estimation method's
  accuracy estimates.
\item
  \textbf{Table XX:}

  \begin{center}
  \begin{tabular}{|c|c|c|c|c|}
  \hline
  Parameter                      & Estimate  & Std. Error & t. Value  & Pr(>|t|) \\
  \hline
  \hline
  Intercept                      &  8.844e-1 &  2.902e-2  &  3.048e1  & <2e-16   \\                             
  \hline
  ID = Pscore                    & -1.409e-1 &  4.104e-2  & -3.433e0  & 8.840e-4 \\
  \hline
  \#Train Obs                    &  1.019e-6 &  1.197e-5  &  8.850e-2 & 9.323e-1 \\
  \hline
  (ID = Pscore):(\#Train Obs) &  1.020e-5 &  1.692e-5  &  6.030e-1 & 5.481e-1 \\
  \hline
  \end{tabular}
  \end{center}

  \textbf{Table XX Caption:} summary table for linear regression trend
  lines fit to accuracy estimate values displayed in \textbf{Figure XX}
\item
  After simulating an outcome using the Inferential Simulation method
  outlined in \textbf{Section (XX)} we compared the accuracy of
  probabilistic scoring and traditional scoring classification methods
  against this outcome for 50 different definitions of training sample
  length.
\item
  The results of this comparison show that traditional scoring
  classification is more accurate than probabilistic scoring for all
  values simulated
\item
  The results indicated that probabilistic scoring accuracy grew at a
  faster rate than traditional scoring accuracy; however these results
  lacked significance (p=0.5581)
\end{itemize}

\hypertarget{probabilistic-simulations}{%
\subsection{Probabilistic Simulations}\label{probabilistic-simulations}}

\begin{itemize}
\item
  \textbf{Figure XX:}

  \begin{center}
  \includegraphics[width=0.5\textwidth]{Sup2Graph.jpg}
  \end{center}
\item
  \textbf{Figure XX Caption:} displays estimated accuracy values for
  probabilistic and traditional scoring classifications as estimated
  using a probabilistically simulated outcome variable, across 50 values
  of training set definitions. Also plotted are Linear Regression trend
  lines for each estimation method's accuracy estimates.
\item
  \textbf{Table XX:}

  \begin{center}
  \begin{tabular}{|c|c|c|c|c|}
  \hline
  Parameter                      & Estimate  & Std. Error & t. Value  & Pr(>|t|) \\
  \hline
  \hline
  Intercept                      &  8.864e-1 &  2.503e-2  &  3.541e1  & <2e-16   \\                             
  \hline
  ID = Traditional               & -8.453e-2 &  3.540e-2  & -2.388e0  & 1.891e-2 \\
  \hline
  \#Train Obs                    &  3.026e-5 &  1.032e-5  &  2.932e0  & 4.210e-3 \\
  \hline
  (ID = Traditional):(\#Train Obs) &  -2.956e-5 &  1.460e-5  &  -2.025e0 & 4.562e-2 \\
  \hline
  \end{tabular}
  \end{center}

  \textbf{Table XX Caption:} summary table for linear regression trend
  lines fit to accuracy estimate values displayed in \textbf{Figure XX}
\item
  After simulating an outcome using the Probabilistic Simulation method
  outlined in \textbf{Section (XX)} we compared the accuracy of
  probabilistic scoring and traditional scoring classification methods
  against this outcome for 50 different definitions of training sample
  length.
\item
  The results of this comparison show that probabilistic scoring
  classification is more accurate than traditional scoring for all
  values simulated
\item
  The results indicated that probabilistic scoring accuracy grew at a
  faster rate than traditional scoring accuracy, and that this effect is
  supported by evidence in the data simulated (p=0.00421)
\end{itemize}

\hypertarget{unsupervised-algorithm-outcomes}{%
\subsection{Unsupervised Algorithm
Outcomes}\label{unsupervised-algorithm-outcomes}}

\hypertarget{kmeans-clustering}{%
\subsubsection{Kmeans Clustering}\label{kmeans-clustering}}

\begin{itemize}
\item
  \textbf{Figure XX:}

  \begin{center}
  \includegraphics[width=0.5\textwidth]{KMeansResultsGraph.jpeg}
  \end{center}
\item
  \textbf{Figure XX:} displays estimated accuracy values for
  probabilistic and traditional scoring classifications as estimated
  using outcomes resulting from a Kmeans clustering process. The
  accuracy values are compared across 50 values of training set
  definitions. Also plotted are Linear Regression trend lines for each
  estimation method's accuracy estimates.
\item
  \textbf{Table XX:}

  \begin{center}
  \begin{tabular}{|c|c|c|c|c|}
  \hline
  Parameter                      & Estimate  & Std. Error & t. Value  & Pr(>|t|) \\
  \hline
  \hline
  Intercept                      &  5.389e-1 &  2.264-2  &  2.380e1  & <2e-16   \\
  \hline
  ID = Traditional               & -4.129e-1 &  3.202e-2  & -1.290e1  & <2e-16 \\
  \hline
  \#Train Obs                    &  -1.483e-6 &  9.321e-6  &  -1.590e-1  & 8.740e-1 \\
  \hline
  (ID = Traditional):(\#Train Obs) &  1.082e-5 &  1.318e-5  &  8.210e-1 & 4.130e-1 \\
  \hline
  \end{tabular}
  \end{center}

  \textbf{Table XX Caption:} summary table for linear regression trend
  lines fit to accuracy estimate values displayed in \textbf{Figure XX}
\item
  We used the outcomes of a Kmeans unsupervised learning algorithm to
  calculate the accuracy of probabilistic scoring and traditional
  scoring classification methods for 50 different definitions of
  training sample length.
\item
  The results of this comparison show that probabilistic scoring
  classification is more accurate than traditional scoring for all
  values simulated
\item
  The results indicated that probabilistic scoring accuracy did not
  continue to grow as training sample size increased; however, the
  estimate of this parameter is not well supported by evidence from the
  data (p=0.874)
\end{itemize}

\hypertarget{hierarchical-clustering}{%
\subsubsection{Hierarchical Clustering}\label{hierarchical-clustering}}

\begin{itemize}
\item
  \textbf{Figure XX:}

  \begin{center}
  \includegraphics[width=0.5\textwidth]{HCResultsGraph.jpeg}
  \end{center}
\item
  \textbf{Figure XX:} displays estimated accuracy values for
  probabilistic and traditional scoring classifications as estimated
  using outcomes resulting from a hierarchical clustering process. The
  accuracy values are compared across 50 values of training set
  definitions. Also plotted are Linear Regression trend lines for each
  estimation method's accuracy estimates.
\item
  \textbf{Table XX:}

  \begin{center}
  \begin{tabular}{|c|c|c|c|c|}
  \hline
  Parameter                      & Estimate  & Std. Error & t. Value  & Pr(>|t|) \\
  \hline
  \hline
  Intercept                      &  3.437e-1 &  2.505e-2  &  1.372e1  & <2e-16   \\
  \hline
  ID = Traditional               & 3.805e-1 &  3.543e-2  & 1.074e1  & <2e-16 \\
  \hline
  \#Train Obs                    &  1.548e-5 &  1.031e-5  &  1.501e0  & 1.350e-1 \\
  \hline
  (ID = Traditional):(\#Train Obs) &  -9.187e-6 &  1.459e-5  &  -6.300e-1 & 5.300e-1 \\
  \hline
  \end{tabular}
  \end{center}

  \textbf{Table XX Caption:} summary table for linear regression trend
  lines fit to accuracy estimate values displayed in \textbf{Figure XX}
\item
  We used the outcomes of a hierarchical clustering learning algorithm
  to calculate the accuracy of probabilistic scoring and traditional
  scoring classification methods for 50 different definitions of
  training sample length.
\item
  The results of this comparison show that traditional scoring
  classification is more accurate than probabilistic scoring for all
  values simulated
\item
  The trend indicated in the probabilistic scoring accuracy over the
  training sample size appeared to indicate that probabilistic scoring
  accuracy increase with training sample size; however, the estimate of
  this parameter is not well supported by evidence from the data
  (p=0.135)
\end{itemize}

\hypertarget{self-organizing-maps-1}{%
\subsubsection{Self Organizing Maps}\label{self-organizing-maps-1}}

\begin{itemize}
\item
  \textbf{Figure XX:}

  \begin{center}
  \includegraphics[width=0.5\textwidth]{SomResultsGraph.jpeg}
  \end{center}
\item
  \textbf{Figure XX Caption:} displays estimated accuracy values for
  probabilistic and traditional scoring classifications obtained using
  outcomes estimated by two Self Organizing Maps that has a 15X15
  lattice structure, a hexagonal topology, and employed either a
  Euclidean or Manhattan Metric. Also plotted are Linear Regression
  trend lines for each estimation method's accuracy estimates.
\item
  \textbf{Table XX:}

  \begin{center}
  \begin{tabular}{|c|c|c|c|c|}
  \hline
  Parameter     & Estimate  & Std. Error & t. Value  & Pr(>|t|) \\
  \hline
  \hline
  Intercept    &  6.227e-1 &  2.814e-2  &  2.213e1  & <2e-16   \\                             
  \hline
  ID = $\left(\text{Pscore}, \ L^{1}  \right)$               & -9.234e-2 &  3.979e-2  & -2.321e0  & 2.136e-2 \\
  \hline
  ID = $\left(\text{Trad}, \ L^{2}   \right)$               & 1.102e-1 &  3.979e-2  & 2.769e0  & 6.170e-3 \\
  \hline
  ID = $\left(\text{Trad}, \ L^{1}   \right)$               & 2.841e-2 &  3.979e-2  & 7.140e-1  & 4.762e-1 \\
  \hline
  \#Train Obs  &  1.781e-5 &  1.60e-5  &  1.535e0  & 1.264e-1 \\
  \hline
  ID = $\left(\text{Pscore}, \ L^{1}  \right)$:(\#Train Obs) &  2.390e-6 &  1.640e-5  &  1.460e-1 & 8.843e-1 \\
  \hline
  ID = $\left(\text{Trad}, \ L^{2}   \right)$:(\#Train Obs) &  -1.557e-5 &  1.640e-5  &  -9.490e-1 & 3.437e-1 \\
  \hline
  ID = $\left(\text{Trad}, \ L^{1}   \right)$:(\#Train Obs) &  -1.593e-5 &  1.640e-5  &  -9.710e0 & 3.329e-1 \\
  \hline
  \end{tabular}
  \end{center}

  \textbf{Table 1 Caption:} summary table for linear regression trend
  lines fit to accuracy estimate values displayed in \textbf{Figure XX}
\item
  We simulated six different outcomes using three different Self
  Organizing Maps with two different metrics. We chose to reduce
  complications by reducing the outcomes we compare the modeling
  accuracies to the two distinct metric forms of SOM2, which exhibited
  the highest accuracies with both traditional scoring and probabilistic
  scoring methods in the \(L^{2}\) metric.
\item
  Comparisons of accuracy between probabilistic and traditional
  classification was performed for each of the two SOMs (two accuracy
  comparisons) on 50 different definitions of training sample length.
\item
  The results of this comparison show that traditional scoring
  classification is more accurate than probabilistic scoring for all
  values simulated.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\hypertarget{summary-of-results}{%
\subsection{Summary of Results}\label{summary-of-results}}

\begin{itemize}
\item
  It is hoped that providing a spectrum of theoretically and empirically
  reasonable accuracy measurements, we can begin to conceptualize those
  values of accuracy that are likely to represent reality.
\item
  We have simulated observation outcomes using information contained in
  data that should reasonably represent outcome values.
\item
  We have performed a comparison of probabilistic and traditional
  scoring accuracy using multiple simulated outcome variables created in
  three different ways.

  \begin{itemize}
  \tightlist
  \item
    Inferential Simulations are based on empirical evidence in the data,
    and theoretical information relating to experimentation
  \item
    Probabilistic Simulations are also based on empirical evidence in
    the data, but also incorporated sequential dependencies in the
    answer sets not accounted for by Inferential Simulations
  \item
    Unsupervised Methods do not account for any underlying
    experimentation practices. These outcomes are generated based upon a
    hierarchy of relations imposed on the results of a clustering
    algorithm.
  \end{itemize}
\item
  Comparisons were evaluated at 50 different definitions of training
  sample length, and trend lines were fit to these calculated accuracy
  values to estimate the relationship between accuracy and training
  sample length.
\item
  The analysis we have conducted must conclude without a definitive
  conclusion on a comparison of probabilistic scoring classification
  accuracy and traditional scoring classification accuracy.

  \begin{itemize}
  \tightlist
  \item
    The analysis evaluated classification accuracy on six different
    simulated outcomes. In two out of these six outcomes, probabilistic
    scoring classification was superior in accuracy.
  \item
    As this answer is not definitive, we will note that the results of
    this analysis apply only with respect to the simulated relationships
    evaluated.
  \end{itemize}
\item
  This analysis has produced initial evidence that probabilistic scoring
  increases with training sample size.
\item
  Out of the six simulated outcome value accuracy comparisons, the
  probabilistic scoring classification accuracy had a higher positive
  trend than did traditional scoring classification accuracy.

  \begin{itemize}
  \tightlist
  \item
    It should be noted that further research is required in order to
    provide a wider-range of estimated training sample set sizes over
    which accuracy can be calculated.
  \end{itemize}
\item
  The sixth (non-greater probabilistic scoring classification accuracy
  trend) belonged to the Kmeans simulated outcome

  \begin{itemize}
  \tightlist
  \item
    This outcome dictated probabilistic scoring as the superior method
    of classification.
  \item
    The interaction between the probabilistic scoring trend and
    traditional scoring trend is weak. Over \(3 \times 10^{4}\)
    observations would be required to make traditional scoring MORE
    accurate in a situation where this outcome represented the truth.
  \item
    In reality, obtaining more observations should not decrease
    probabilistic scoring accuracy. However, increasing observational
    counts will increase initialization dependencies in the Kmeans
    algorithm. Therefore, the decrease in probabilistic scoring
    classification accuracy could be explained by a tendency of the
    outcome variable to ``shift its preference'' when different data
    sizes are provided.
  \end{itemize}
\end{itemize}

\hypertarget{client-satisfaction-concerns}{%
\subsection{Client Satisfaction
Concerns}\label{client-satisfaction-concerns}}

\begin{itemize}
\tightlist
\item
  As initially specified, this analysis has not come close to answering
  either of the client-specified goals.
\item
  Mathematical proof aside, this analysis has failed to produce any
  concrete comparison of probabilistic and traditional scoring
  accuracies.
\item
  The CV analysis has also failed to produce reliable results and needs
  to be adapted to allow for more flexible sampling practices.
\item
  The specified analysis does not address or even acknowledge the
  client's second stated goal.
\end{itemize}

\hypertarget{next-steps}{%
\subsection{Next Steps}\label{next-steps}}

\begin{itemize}
\tightlist
\item
  Although this approach might be enlightening, finishing touches are
  most likely not advisable as they will most likely not produce
  conclusive results.
\item
  However, further analysis would include altering the CV analysis
  process to re-distribute the values of training sample length to a
  wider and better representative spectrum.

  \begin{itemize}
  \tightlist
  \item
    Improvements could be easily implemented by independently sampling
    Test and Training sets, and replacing observations as sampling takes
    place.
  \item
    The new process would allow for potentially infinite (although
    practically fewer) Train/Test sample size pairings.
  \item
    The distribution of Training sample size could also be easily
    regulated, and even sequentially spaced.
  \end{itemize}
\item
  Self Organizing Maps have improved algorithms which allow for the
  structure on which they are built to be ``optimized''. This so called
  ``Growing Self Organizing Map'' (GSOM) would better capture
  information in the original data than pre-specified structures.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{data-and-code-availability}{%
\subsection{Data and Code
Availability}\label{data-and-code-availability}}

Access to code, with instructions, and all data used for the analysis
completed here is available for download at:

\texttt{https://github.com/leepanter/PScoreVSTscore}

\texttt{git@github.com:leepanter/PScoreVSTscore.git}

\begin{itemize}
\tightlist
\item
  \textbf{Necessary code or software instructions to carry our your analysis.}
\item
  \textbf{Include any resources you have referred to or found helpful}
\item
  \textbf{If appropriate, include other deliverables}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{references}{%
\section{References}\label{references}}

\bibliography{Bib_AccRefSheet}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-kroenke2002phq}{}%
1. Kroenke K, Spitzer RL (2002) The phq-9: A new depression diagnostic
and severity measure. \emph{Psychiatric annals} 32: 509--515.

\leavevmode\hypertarget{ref-kroenke2010instruction}{}%
2. Kroenke K, Spitzer R (2010) Instruction manual: Instructions for
patient health questionnaire (phq) and gad-7 measures.

\leavevmode\hypertarget{ref-MalikMoreEf}{}%
3. Malik A More effective and cost effective use of the phq-9.

\leavevmode\hypertarget{ref-kroenke16spitzer}{}%
4. Kroenke K Spitzer, rl \& williams, jb (2001). The phq-9.
\emph{Journal of General Internal Medicine} 16: 606--613.

\leavevmode\hypertarget{ref-STHDA_2020}{}%
5. (2020) \emph{Sthdacom}.

\leavevmode\hypertarget{ref-Belavkin}{}%
6. Belavkin R Lecture 13: Self-organising maps.

\leavevmode\hypertarget{ref-Tanner_2020}{}%
7. Tanner D (2020) Introduction to self organizing maps in r - the
kohonen package and nba player statistics. \emph{Githubio}.


\end{document}
